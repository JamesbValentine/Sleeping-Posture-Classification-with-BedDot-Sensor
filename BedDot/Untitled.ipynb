{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14465d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 14:47:22.454418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from utilities import *\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import keras\n",
    "import utils.augmentation as aug\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, dataset = load_larger_dataset_first_scenario()\n",
    "train_set_y = transform_label(train_set_y_orig)\n",
    "test_set_y = transform_label(test_set_y_orig)\n",
    "Y = pd.get_dummies(train_set_y)\n",
    "Y = Y.replace({True: 1, False: 0}).astype(float)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to your dataframe and transform it\n",
    "train_x_std = scaler.fit_transform(train_set_x_orig)\n",
    "train_x = pd.DataFrame(train_x_std)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# fit the scaler to your dataframe and transform it\n",
    "test_x_std = scaler.fit_transform(test_set_x_orig)\n",
    "test_x = pd.DataFrame(test_x_std)\n",
    "test_set_y = transform_label(test_set_y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf1b6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535068</td>\n",
       "      <td>0.224282</td>\n",
       "      <td>-0.148606</td>\n",
       "      <td>-0.343657</td>\n",
       "      <td>-0.641576</td>\n",
       "      <td>-0.832988</td>\n",
       "      <td>-0.849029</td>\n",
       "      <td>-0.744321</td>\n",
       "      <td>-0.828458</td>\n",
       "      <td>-0.548708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886991</td>\n",
       "      <td>-1.583172</td>\n",
       "      <td>-1.930889</td>\n",
       "      <td>-1.827324</td>\n",
       "      <td>-1.647419</td>\n",
       "      <td>-1.374463</td>\n",
       "      <td>-0.844228</td>\n",
       "      <td>-0.249675</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>0.724039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.499316</td>\n",
       "      <td>-1.648444</td>\n",
       "      <td>-1.646612</td>\n",
       "      <td>-1.490652</td>\n",
       "      <td>-1.129920</td>\n",
       "      <td>-0.743790</td>\n",
       "      <td>-0.354456</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.717596</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.206499</td>\n",
       "      <td>-1.225544</td>\n",
       "      <td>-1.184891</td>\n",
       "      <td>-1.144239</td>\n",
       "      <td>-1.103587</td>\n",
       "      <td>-1.057802</td>\n",
       "      <td>-0.954709</td>\n",
       "      <td>-0.851617</td>\n",
       "      <td>-0.748524</td>\n",
       "      <td>-0.645431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608131</td>\n",
       "      <td>-0.050384</td>\n",
       "      <td>-0.616007</td>\n",
       "      <td>-0.035738</td>\n",
       "      <td>0.716734</td>\n",
       "      <td>0.455001</td>\n",
       "      <td>0.054995</td>\n",
       "      <td>0.368301</td>\n",
       "      <td>0.901938</td>\n",
       "      <td>0.914435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255456</td>\n",
       "      <td>0.406873</td>\n",
       "      <td>0.501187</td>\n",
       "      <td>0.464024</td>\n",
       "      <td>0.291978</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>-0.120632</td>\n",
       "      <td>-0.246743</td>\n",
       "      <td>-0.211486</td>\n",
       "      <td>-0.243234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412884</td>\n",
       "      <td>0.699084</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>0.866684</td>\n",
       "      <td>0.674207</td>\n",
       "      <td>0.750674</td>\n",
       "      <td>1.066309</td>\n",
       "      <td>1.165676</td>\n",
       "      <td>1.299208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835677</td>\n",
       "      <td>1.359029</td>\n",
       "      <td>1.711895</td>\n",
       "      <td>2.120469</td>\n",
       "      <td>2.528132</td>\n",
       "      <td>2.576589</td>\n",
       "      <td>2.508295</td>\n",
       "      <td>2.659422</td>\n",
       "      <td>2.750255</td>\n",
       "      <td>2.705510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.199303</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>0.170967</td>\n",
       "      <td>0.362338</td>\n",
       "      <td>0.450999</td>\n",
       "      <td>0.507196</td>\n",
       "      <td>0.510352</td>\n",
       "      <td>0.451951</td>\n",
       "      <td>0.388107</td>\n",
       "      <td>0.409840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591117</td>\n",
       "      <td>-0.975192</td>\n",
       "      <td>-1.172449</td>\n",
       "      <td>-1.211592</td>\n",
       "      <td>-1.144271</td>\n",
       "      <td>-1.008544</td>\n",
       "      <td>-0.813823</td>\n",
       "      <td>-0.585806</td>\n",
       "      <td>-0.318387</td>\n",
       "      <td>-0.073820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101524</th>\n",
       "      <td>-1.088429</td>\n",
       "      <td>0.478959</td>\n",
       "      <td>-0.388813</td>\n",
       "      <td>0.155228</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.363965</td>\n",
       "      <td>0.247225</td>\n",
       "      <td>-0.124501</td>\n",
       "      <td>-0.458463</td>\n",
       "      <td>-0.492913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620969</td>\n",
       "      <td>0.608102</td>\n",
       "      <td>0.581827</td>\n",
       "      <td>0.507992</td>\n",
       "      <td>0.360719</td>\n",
       "      <td>0.215012</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>-0.119154</td>\n",
       "      <td>-0.373286</td>\n",
       "      <td>0.258582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101525</th>\n",
       "      <td>-0.160244</td>\n",
       "      <td>-0.220867</td>\n",
       "      <td>-0.232420</td>\n",
       "      <td>-0.235409</td>\n",
       "      <td>-0.231867</td>\n",
       "      <td>-0.171195</td>\n",
       "      <td>-0.070304</td>\n",
       "      <td>-0.010100</td>\n",
       "      <td>0.057378</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936614</td>\n",
       "      <td>-0.656393</td>\n",
       "      <td>-0.225870</td>\n",
       "      <td>0.284487</td>\n",
       "      <td>0.819240</td>\n",
       "      <td>1.257953</td>\n",
       "      <td>1.465637</td>\n",
       "      <td>1.376219</td>\n",
       "      <td>1.073314</td>\n",
       "      <td>0.716656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101526</th>\n",
       "      <td>-0.543972</td>\n",
       "      <td>-1.173676</td>\n",
       "      <td>-1.391533</td>\n",
       "      <td>-1.352929</td>\n",
       "      <td>-1.129094</td>\n",
       "      <td>-0.627628</td>\n",
       "      <td>0.127884</td>\n",
       "      <td>0.892266</td>\n",
       "      <td>1.395359</td>\n",
       "      <td>1.625065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.961019</td>\n",
       "      <td>-1.262628</td>\n",
       "      <td>-1.478092</td>\n",
       "      <td>-1.373828</td>\n",
       "      <td>-0.943276</td>\n",
       "      <td>-0.404369</td>\n",
       "      <td>0.091978</td>\n",
       "      <td>0.599739</td>\n",
       "      <td>1.099323</td>\n",
       "      <td>1.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101527</th>\n",
       "      <td>0.014380</td>\n",
       "      <td>-0.173665</td>\n",
       "      <td>-0.347415</td>\n",
       "      <td>-0.483362</td>\n",
       "      <td>-0.543021</td>\n",
       "      <td>-0.509849</td>\n",
       "      <td>-0.391189</td>\n",
       "      <td>-0.213885</td>\n",
       "      <td>-0.014706</td>\n",
       "      <td>0.177145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276303</td>\n",
       "      <td>0.171056</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.545690</td>\n",
       "      <td>-0.969520</td>\n",
       "      <td>-0.998621</td>\n",
       "      <td>-0.856398</td>\n",
       "      <td>-0.722979</td>\n",
       "      <td>-0.525605</td>\n",
       "      <td>-0.525605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101528</th>\n",
       "      <td>-0.338089</td>\n",
       "      <td>-0.165118</td>\n",
       "      <td>-0.043827</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>0.407321</td>\n",
       "      <td>0.535346</td>\n",
       "      <td>0.785920</td>\n",
       "      <td>1.077147</td>\n",
       "      <td>1.167933</td>\n",
       "      <td>1.074184</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142770</td>\n",
       "      <td>1.780996</td>\n",
       "      <td>2.025347</td>\n",
       "      <td>1.836318</td>\n",
       "      <td>1.354437</td>\n",
       "      <td>0.684894</td>\n",
       "      <td>0.058557</td>\n",
       "      <td>-0.372449</td>\n",
       "      <td>-0.575779</td>\n",
       "      <td>-0.615308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101529 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6     \n",
       "0       0.535068  0.224282 -0.148606 -0.343657 -0.641576 -0.832988 -0.849029  \\\n",
       "1      -1.499316 -1.648444 -1.646612 -1.490652 -1.129920 -0.743790 -0.354456   \n",
       "2       0.608131 -0.050384 -0.616007 -0.035738  0.716734  0.455001  0.054995   \n",
       "3       0.412884  0.699084  0.827273  0.939424  0.866684  0.674207  0.750674   \n",
       "4      -0.199303 -0.003597  0.170967  0.362338  0.450999  0.507196  0.510352   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "101524 -1.088429  0.478959 -0.388813  0.155228  0.138917  0.363965  0.247225   \n",
       "101525 -0.160244 -0.220867 -0.232420 -0.235409 -0.231867 -0.171195 -0.070304   \n",
       "101526 -0.543972 -1.173676 -1.391533 -1.352929 -1.129094 -0.627628  0.127884   \n",
       "101527  0.014380 -0.173665 -0.347415 -0.483362 -0.543021 -0.509849 -0.391189   \n",
       "101528 -0.338089 -0.165118 -0.043827  0.172078  0.407321  0.535346  0.785920   \n",
       "\n",
       "             7         8         9    ...       990       991       992   \n",
       "0      -0.744321 -0.828458 -0.548708  ... -0.886991 -1.583172 -1.930889  \\\n",
       "1       0.030432  0.396167  0.717596  ... -1.206499 -1.225544 -1.184891   \n",
       "2       0.368301  0.901938  0.914435  ...  0.255456  0.406873  0.501187   \n",
       "3       1.066309  1.165676  1.299208  ...  0.835677  1.359029  1.711895   \n",
       "4       0.451951  0.388107  0.409840  ... -0.591117 -0.975192 -1.172449   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "101524 -0.124501 -0.458463 -0.492913  ...  0.620969  0.608102  0.581827   \n",
       "101525 -0.010100  0.057378  0.146924  ... -0.936614 -0.656393 -0.225870   \n",
       "101526  0.892266  1.395359  1.625065  ... -0.961019 -1.262628 -1.478092   \n",
       "101527 -0.213885 -0.014706  0.177145  ...  0.276303  0.171056  0.000233   \n",
       "101528  1.077147  1.167933  1.074184  ...  1.142770  1.780996  2.025347   \n",
       "\n",
       "             993       994       995       996       997       998       999  \n",
       "0      -1.827324 -1.647419 -1.374463 -0.844228 -0.249675  0.110226  0.724039  \n",
       "1      -1.144239 -1.103587 -1.057802 -0.954709 -0.851617 -0.748524 -0.645431  \n",
       "2       0.464024  0.291978  0.051802 -0.120632 -0.246743 -0.211486 -0.243234  \n",
       "3       2.120469  2.528132  2.576589  2.508295  2.659422  2.750255  2.705510  \n",
       "4      -1.211592 -1.144271 -1.008544 -0.813823 -0.585806 -0.318387 -0.073820  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "101524  0.507992  0.360719  0.215012  0.071593 -0.119154 -0.373286  0.258582  \n",
       "101525  0.284487  0.819240  1.257953  1.465637  1.376219  1.073314  0.716656  \n",
       "101526 -1.373828 -0.943276 -0.404369  0.091978  0.599739  1.099323  1.099323  \n",
       "101527 -0.545690 -0.969520 -0.998621 -0.856398 -0.722979 -0.525605 -0.525605  \n",
       "101528  1.836318  1.354437  0.684894  0.058557 -0.372449 -0.575779 -0.615308  \n",
       "\n",
       "[101529 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add augmented data into training set\n",
    "augmentation_train_set = augment_training_set(train_x, train_set_y)\n",
    "augmentation_train_x = augmentation_train_set.iloc[:, :1000]\n",
    "augmentation_train_y = augmentation_train_set.iloc[:, 1000]\n",
    "\n",
    "augmentation_train_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60dedc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         0.0\n",
       "2         2.0\n",
       "3         0.0\n",
       "4         3.0\n",
       "         ... \n",
       "101524    0.0\n",
       "101525    2.0\n",
       "101526    0.0\n",
       "101527    3.0\n",
       "101528    0.0\n",
       "Name: 1000, Length: 101529, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c866336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to your dataframe and transform it\n",
    "augmentation_train_x_std = scaler.fit_transform(augmentation_train_x)\n",
    "augmentation_train_x = pd.DataFrame(augmentation_train_x_std)\n",
    "\n",
    "# one-hot encoding\n",
    "augmentation_Y = pd.get_dummies(augmentation_train_y)\n",
    "augmentation_Y = augmentation_Y.replace({True: 1, False: 0}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e1446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "clf_multiclass = LGBMClassifier()\n",
    "clf_multiclass.fit(augmentation_train_x, augmentation_train_y)\n",
    "val_pred = clf_multiclass.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78af53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6088934850051706 668.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_set_y,val_pred), np.sum(val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e9cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2893  429 1090  120]\n",
      " [  41   33   21   24]\n",
      " [   3    0    0    0]\n",
      " [ 142   12    9   18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "NN_confusion_matrix = confusion_matrix(test_set_y, val_pred).T\n",
    "print(NN_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2beeee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 67686, number of used features: 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 67686, number of used features: 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 67686, number of used features: 1000\n",
      "[LightGBM] [Info] Start training from score -0.648846\n",
      "[LightGBM] [Info] Start training from score -2.080950\n",
      "[LightGBM] [Info] Start training from score -2.050867\n",
      "[LightGBM] [Info] Start training from score -1.496483\n",
      "[LightGBM] [Info] Start training from score -0.648846\n",
      "[LightGBM] [Info] Start training from score -2.080950\n",
      "[LightGBM] [Info] Start training from score -2.050867\n",
      "[LightGBM] [Info] Start training from score -1.496483\n",
      "[LightGBM] [Info] Start training from score -0.648846\n",
      "[LightGBM] [Info] Start training from score -2.080950\n",
      "[LightGBM] [Info] Start training from score -2.050867\n",
      "[LightGBM] [Info] Start training from score -1.496483\n",
      "[20]\tcv_agg's multi_logloss: 1.18451 + 0.00034662\n",
      "[40]\tcv_agg's multi_logloss: 1.17246 + 0.000371933\n",
      "[60]\tcv_agg's multi_logloss: 1.16132 + 0.000298168\n",
      "[80]\tcv_agg's multi_logloss: 1.151 + 0.00026957\n",
      "[100]\tcv_agg's multi_logloss: 1.14137 + 0.000244824\n",
      "[120]\tcv_agg's multi_logloss: 1.13251 + 0.000132088\n",
      "[140]\tcv_agg's multi_logloss: 1.12416 + 0.000393368\n",
      "[160]\tcv_agg's multi_logloss: 1.11588 + 0.000607801\n",
      "[180]\tcv_agg's multi_logloss: 1.10809 + 0.000628748\n",
      "[200]\tcv_agg's multi_logloss: 1.10073 + 0.000433558\n",
      "[220]\tcv_agg's multi_logloss: 1.09369 + 0.000296968\n",
      "[240]\tcv_agg's multi_logloss: 1.08691 + 0.000315728\n",
      "[260]\tcv_agg's multi_logloss: 1.08021 + 0.000360744\n",
      "[280]\tcv_agg's multi_logloss: 1.07375 + 0.000423604\n",
      "[300]\tcv_agg's multi_logloss: 1.0678 + 0.000539831\n",
      "[320]\tcv_agg's multi_logloss: 1.06188 + 0.000665398\n",
      "[340]\tcv_agg's multi_logloss: 1.05613 + 0.000669605\n",
      "[360]\tcv_agg's multi_logloss: 1.05062 + 0.000622866\n",
      "[380]\tcv_agg's multi_logloss: 1.04515 + 0.000636485\n",
      "[400]\tcv_agg's multi_logloss: 1.03984 + 0.000636509\n",
      "[420]\tcv_agg's multi_logloss: 1.03472 + 0.000526252\n",
      "[440]\tcv_agg's multi_logloss: 1.02976 + 0.00043591\n",
      "[460]\tcv_agg's multi_logloss: 1.025 + 0.000484382\n",
      "[480]\tcv_agg's multi_logloss: 1.02025 + 0.00046392\n",
      "[500]\tcv_agg's multi_logloss: 1.01557 + 0.00055251\n",
      "[520]\tcv_agg's multi_logloss: 1.01114 + 0.000582649\n",
      "[540]\tcv_agg's multi_logloss: 1.00671 + 0.000698349\n",
      "[560]\tcv_agg's multi_logloss: 1.00242 + 0.000660808\n",
      "[580]\tcv_agg's multi_logloss: 0.998264 + 0.000502757\n",
      "[600]\tcv_agg's multi_logloss: 0.994211 + 0.000468779\n",
      "[620]\tcv_agg's multi_logloss: 0.990305 + 0.000536067\n",
      "[640]\tcv_agg's multi_logloss: 0.986321 + 0.000590639\n",
      "[660]\tcv_agg's multi_logloss: 0.982421 + 0.00072074\n",
      "[680]\tcv_agg's multi_logloss: 0.978642 + 0.000722448\n",
      "[700]\tcv_agg's multi_logloss: 0.974951 + 0.000655248\n",
      "[720]\tcv_agg's multi_logloss: 0.971375 + 0.000602114\n",
      "[740]\tcv_agg's multi_logloss: 0.967827 + 0.000693641\n",
      "[760]\tcv_agg's multi_logloss: 0.96438 + 0.00061739\n",
      "[780]\tcv_agg's multi_logloss: 0.96093 + 0.00059353\n",
      "[800]\tcv_agg's multi_logloss: 0.957526 + 0.000598827\n",
      "[820]\tcv_agg's multi_logloss: 0.954309 + 0.000592278\n",
      "[840]\tcv_agg's multi_logloss: 0.951121 + 0.000542625\n",
      "[860]\tcv_agg's multi_logloss: 0.948017 + 0.000542131\n",
      "[880]\tcv_agg's multi_logloss: 0.944921 + 0.000553979\n",
      "[900]\tcv_agg's multi_logloss: 0.941864 + 0.000590629\n",
      "[920]\tcv_agg's multi_logloss: 0.938913 + 0.00057215\n",
      "[940]\tcv_agg's multi_logloss: 0.935835 + 0.000549112\n",
      "[960]\tcv_agg's multi_logloss: 0.932878 + 0.000582818\n",
      "[980]\tcv_agg's multi_logloss: 0.9299 + 0.000467275\n",
      "[1000]\tcv_agg's multi_logloss: 0.927014 + 0.000448122\n",
      "[1020]\tcv_agg's multi_logloss: 0.92421 + 0.000407345\n",
      "[1040]\tcv_agg's multi_logloss: 0.921371 + 0.000399901\n",
      "[1060]\tcv_agg's multi_logloss: 0.918548 + 0.000437098\n",
      "[1080]\tcv_agg's multi_logloss: 0.915829 + 0.000467617\n",
      "[1100]\tcv_agg's multi_logloss: 0.913098 + 0.000529672\n",
      "[1120]\tcv_agg's multi_logloss: 0.910518 + 0.000610773\n",
      "[1140]\tcv_agg's multi_logloss: 0.907892 + 0.000607323\n",
      "[1160]\tcv_agg's multi_logloss: 0.905222 + 0.000734972\n",
      "[1180]\tcv_agg's multi_logloss: 0.902653 + 0.000698065\n",
      "[1200]\tcv_agg's multi_logloss: 0.900209 + 0.000665895\n",
      "[1220]\tcv_agg's multi_logloss: 0.897712 + 0.000694504\n",
      "[1240]\tcv_agg's multi_logloss: 0.89516 + 0.000674247\n",
      "[1260]\tcv_agg's multi_logloss: 0.892717 + 0.000623201\n",
      "[1280]\tcv_agg's multi_logloss: 0.89035 + 0.000589457\n",
      "[1300]\tcv_agg's multi_logloss: 0.887956 + 0.000603937\n",
      "[1320]\tcv_agg's multi_logloss: 0.885583 + 0.000666995\n",
      "[1340]\tcv_agg's multi_logloss: 0.883258 + 0.000830814\n",
      "[1360]\tcv_agg's multi_logloss: 0.881004 + 0.000851533\n",
      "[1380]\tcv_agg's multi_logloss: 0.878676 + 0.00102469\n",
      "[1400]\tcv_agg's multi_logloss: 0.876551 + 0.00103273\n",
      "[1420]\tcv_agg's multi_logloss: 0.874328 + 0.00106362\n",
      "[1440]\tcv_agg's multi_logloss: 0.872151 + 0.00102769\n",
      "[1460]\tcv_agg's multi_logloss: 0.87003 + 0.000987671\n",
      "[1480]\tcv_agg's multi_logloss: 0.867794 + 0.00103088\n",
      "[1500]\tcv_agg's multi_logloss: 0.865771 + 0.000992116\n",
      "[1520]\tcv_agg's multi_logloss: 0.863528 + 0.000952738\n",
      "[1540]\tcv_agg's multi_logloss: 0.861372 + 0.000978089\n",
      "[1560]\tcv_agg's multi_logloss: 0.859281 + 0.00100424\n",
      "[1580]\tcv_agg's multi_logloss: 0.857269 + 0.00102312\n",
      "[1600]\tcv_agg's multi_logloss: 0.855267 + 0.000986375\n",
      "[1620]\tcv_agg's multi_logloss: 0.853337 + 0.00104749\n",
      "[1640]\tcv_agg's multi_logloss: 0.851337 + 0.00101507\n",
      "[1660]\tcv_agg's multi_logloss: 0.849384 + 0.000996585\n",
      "[1680]\tcv_agg's multi_logloss: 0.84749 + 0.00101656\n",
      "[1700]\tcv_agg's multi_logloss: 0.845578 + 0.0010138\n",
      "[1720]\tcv_agg's multi_logloss: 0.843573 + 0.00105002\n",
      "[1740]\tcv_agg's multi_logloss: 0.841761 + 0.00110959\n",
      "[1760]\tcv_agg's multi_logloss: 0.839848 + 0.00113122\n",
      "[1780]\tcv_agg's multi_logloss: 0.837928 + 0.00109012\n",
      "[1800]\tcv_agg's multi_logloss: 0.836114 + 0.00114841\n",
      "[1820]\tcv_agg's multi_logloss: 0.834254 + 0.00116034\n",
      "[1840]\tcv_agg's multi_logloss: 0.832366 + 0.0011281\n",
      "[1860]\tcv_agg's multi_logloss: 0.830595 + 0.00114588\n",
      "[1880]\tcv_agg's multi_logloss: 0.828776 + 0.00108657\n",
      "[1900]\tcv_agg's multi_logloss: 0.827 + 0.00114558\n",
      "[1920]\tcv_agg's multi_logloss: 0.825259 + 0.00123357\n",
      "[1940]\tcv_agg's multi_logloss: 0.823514 + 0.00122382\n",
      "[1960]\tcv_agg's multi_logloss: 0.821725 + 0.00123968\n",
      "[1980]\tcv_agg's multi_logloss: 0.82001 + 0.00123635\n",
      "[2000]\tcv_agg's multi_logloss: 0.818349 + 0.00119928\n",
      "[2020]\tcv_agg's multi_logloss: 0.816733 + 0.00118629\n",
      "[2040]\tcv_agg's multi_logloss: 0.815048 + 0.00118694\n",
      "[2060]\tcv_agg's multi_logloss: 0.813412 + 0.00116029\n",
      "[2080]\tcv_agg's multi_logloss: 0.811656 + 0.00119971\n",
      "[2100]\tcv_agg's multi_logloss: 0.810049 + 0.00123717\n",
      "[2120]\tcv_agg's multi_logloss: 0.808346 + 0.00127958\n",
      "[2140]\tcv_agg's multi_logloss: 0.806705 + 0.00121629\n",
      "[2160]\tcv_agg's multi_logloss: 0.805065 + 0.00125317\n",
      "[2180]\tcv_agg's multi_logloss: 0.80346 + 0.00125136\n",
      "[2200]\tcv_agg's multi_logloss: 0.801908 + 0.00124678\n",
      "[2220]\tcv_agg's multi_logloss: 0.800327 + 0.00130054\n",
      "[2240]\tcv_agg's multi_logloss: 0.79875 + 0.00130048\n",
      "[2260]\tcv_agg's multi_logloss: 0.797182 + 0.00132764\n",
      "[2280]\tcv_agg's multi_logloss: 0.795652 + 0.00133237\n",
      "[2300]\tcv_agg's multi_logloss: 0.794169 + 0.00123885\n",
      "[2320]\tcv_agg's multi_logloss: 0.792725 + 0.00125215\n",
      "[2340]\tcv_agg's multi_logloss: 0.791169 + 0.00118949\n",
      "[2360]\tcv_agg's multi_logloss: 0.789689 + 0.00123282\n",
      "[2380]\tcv_agg's multi_logloss: 0.788178 + 0.00124097\n",
      "[2400]\tcv_agg's multi_logloss: 0.786693 + 0.00124804\n",
      "[2420]\tcv_agg's multi_logloss: 0.785292 + 0.00130058\n",
      "[2440]\tcv_agg's multi_logloss: 0.783857 + 0.00134455\n",
      "[2460]\tcv_agg's multi_logloss: 0.782395 + 0.00135004\n",
      "[2480]\tcv_agg's multi_logloss: 0.780927 + 0.00133154\n",
      "[2500]\tcv_agg's multi_logloss: 0.779513 + 0.00132585\n",
      "[2520]\tcv_agg's multi_logloss: 0.778179 + 0.00132538\n",
      "[2540]\tcv_agg's multi_logloss: 0.776787 + 0.00131622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2560]\tcv_agg's multi_logloss: 0.775367 + 0.00132283\n",
      "[2580]\tcv_agg's multi_logloss: 0.773989 + 0.00131812\n",
      "[2600]\tcv_agg's multi_logloss: 0.772638 + 0.00129002\n",
      "[2620]\tcv_agg's multi_logloss: 0.771301 + 0.00128492\n",
      "[2640]\tcv_agg's multi_logloss: 0.769942 + 0.00130525\n",
      "[2660]\tcv_agg's multi_logloss: 0.768606 + 0.00129665\n",
      "[2680]\tcv_agg's multi_logloss: 0.767266 + 0.00124617\n",
      "[2700]\tcv_agg's multi_logloss: 0.765963 + 0.00127058\n",
      "[2720]\tcv_agg's multi_logloss: 0.764639 + 0.00127372\n",
      "[2740]\tcv_agg's multi_logloss: 0.763307 + 0.00128347\n",
      "[2760]\tcv_agg's multi_logloss: 0.76204 + 0.00132188\n",
      "[2780]\tcv_agg's multi_logloss: 0.760792 + 0.00135864\n",
      "[2800]\tcv_agg's multi_logloss: 0.75956 + 0.00138469\n",
      "[2820]\tcv_agg's multi_logloss: 0.758286 + 0.00142205\n",
      "[2840]\tcv_agg's multi_logloss: 0.757059 + 0.00138414\n",
      "[2860]\tcv_agg's multi_logloss: 0.755717 + 0.00145048\n",
      "[2880]\tcv_agg's multi_logloss: 0.754434 + 0.00148879\n",
      "[2900]\tcv_agg's multi_logloss: 0.753206 + 0.0015442\n",
      "[2920]\tcv_agg's multi_logloss: 0.752012 + 0.00159255\n",
      "[2940]\tcv_agg's multi_logloss: 0.750761 + 0.0016187\n",
      "[2960]\tcv_agg's multi_logloss: 0.749528 + 0.00162731\n",
      "[2980]\tcv_agg's multi_logloss: 0.748321 + 0.00163759\n",
      "[3000]\tcv_agg's multi_logloss: 0.747119 + 0.00160053\n",
      "[3020]\tcv_agg's multi_logloss: 0.745867 + 0.00160289\n",
      "[3040]\tcv_agg's multi_logloss: 0.744664 + 0.00155575\n",
      "[3060]\tcv_agg's multi_logloss: 0.743441 + 0.00156319\n",
      "[3080]\tcv_agg's multi_logloss: 0.742252 + 0.0015802\n",
      "[3100]\tcv_agg's multi_logloss: 0.741118 + 0.00166704\n",
      "[3120]\tcv_agg's multi_logloss: 0.739959 + 0.00169913\n",
      "[3140]\tcv_agg's multi_logloss: 0.738775 + 0.00171608\n",
      "[3160]\tcv_agg's multi_logloss: 0.737668 + 0.0016929\n",
      "[3180]\tcv_agg's multi_logloss: 0.736523 + 0.00171037\n",
      "[3200]\tcv_agg's multi_logloss: 0.735382 + 0.00175023\n",
      "[3220]\tcv_agg's multi_logloss: 0.734261 + 0.00181062\n",
      "[3240]\tcv_agg's multi_logloss: 0.733146 + 0.00177526\n",
      "[3260]\tcv_agg's multi_logloss: 0.73202 + 0.00174701\n",
      "[3280]\tcv_agg's multi_logloss: 0.730872 + 0.00175772\n",
      "[3300]\tcv_agg's multi_logloss: 0.729818 + 0.00177794\n",
      "[3320]\tcv_agg's multi_logloss: 0.728674 + 0.00174621\n",
      "[3340]\tcv_agg's multi_logloss: 0.727535 + 0.00171972\n",
      "[3360]\tcv_agg's multi_logloss: 0.726466 + 0.00171492\n",
      "[3380]\tcv_agg's multi_logloss: 0.725385 + 0.00167241\n",
      "[3400]\tcv_agg's multi_logloss: 0.72432 + 0.00170537\n",
      "[3420]\tcv_agg's multi_logloss: 0.723282 + 0.00174612\n",
      "[3440]\tcv_agg's multi_logloss: 0.722243 + 0.00175591\n",
      "[3460]\tcv_agg's multi_logloss: 0.721177 + 0.00178897\n",
      "[3480]\tcv_agg's multi_logloss: 0.720102 + 0.00181666\n",
      "[3500]\tcv_agg's multi_logloss: 0.719021 + 0.00183729\n",
      "[3520]\tcv_agg's multi_logloss: 0.717917 + 0.00185084\n",
      "[3540]\tcv_agg's multi_logloss: 0.716855 + 0.00184786\n",
      "[3560]\tcv_agg's multi_logloss: 0.715767 + 0.00188578\n",
      "[3580]\tcv_agg's multi_logloss: 0.714738 + 0.00186624\n",
      "[3600]\tcv_agg's multi_logloss: 0.713694 + 0.00186261\n",
      "[3620]\tcv_agg's multi_logloss: 0.712641 + 0.0019059\n",
      "[3640]\tcv_agg's multi_logloss: 0.711642 + 0.00188045\n",
      "[3660]\tcv_agg's multi_logloss: 0.7107 + 0.00187597\n",
      "[3680]\tcv_agg's multi_logloss: 0.709715 + 0.00188923\n",
      "[3700]\tcv_agg's multi_logloss: 0.708736 + 0.00189599\n",
      "[3720]\tcv_agg's multi_logloss: 0.707772 + 0.00185997\n",
      "[3740]\tcv_agg's multi_logloss: 0.706771 + 0.00187426\n",
      "[3760]\tcv_agg's multi_logloss: 0.705844 + 0.00190825\n",
      "[3780]\tcv_agg's multi_logloss: 0.704884 + 0.00191809\n",
      "[3800]\tcv_agg's multi_logloss: 0.703893 + 0.00191741\n",
      "[3820]\tcv_agg's multi_logloss: 0.702894 + 0.00193177\n",
      "[3840]\tcv_agg's multi_logloss: 0.701986 + 0.00196647\n",
      "[3860]\tcv_agg's multi_logloss: 0.701069 + 0.00194974\n",
      "[3880]\tcv_agg's multi_logloss: 0.700124 + 0.00195553\n",
      "[3900]\tcv_agg's multi_logloss: 0.69915 + 0.00193595\n",
      "[3920]\tcv_agg's multi_logloss: 0.698223 + 0.00194657\n",
      "[3940]\tcv_agg's multi_logloss: 0.697305 + 0.00196422\n",
      "[3960]\tcv_agg's multi_logloss: 0.696387 + 0.00194528\n",
      "[3980]\tcv_agg's multi_logloss: 0.695525 + 0.00197162\n",
      "[4000]\tcv_agg's multi_logloss: 0.694641 + 0.00196947\n",
      "[4020]\tcv_agg's multi_logloss: 0.693752 + 0.00199439\n",
      "[4040]\tcv_agg's multi_logloss: 0.692863 + 0.00204018\n",
      "[4060]\tcv_agg's multi_logloss: 0.691949 + 0.0020507\n",
      "[4080]\tcv_agg's multi_logloss: 0.691084 + 0.00205402\n",
      "[4100]\tcv_agg's multi_logloss: 0.690195 + 0.00202922\n",
      "[4120]\tcv_agg's multi_logloss: 0.689334 + 0.00203971\n",
      "[4140]\tcv_agg's multi_logloss: 0.688464 + 0.00202387\n",
      "[4160]\tcv_agg's multi_logloss: 0.687647 + 0.00203546\n",
      "[4180]\tcv_agg's multi_logloss: 0.686762 + 0.00202165\n",
      "[4200]\tcv_agg's multi_logloss: 0.685959 + 0.0020652\n",
      "[4220]\tcv_agg's multi_logloss: 0.685092 + 0.00203619\n",
      "[4240]\tcv_agg's multi_logloss: 0.684233 + 0.00205926\n",
      "[4260]\tcv_agg's multi_logloss: 0.683393 + 0.00206656\n",
      "[4280]\tcv_agg's multi_logloss: 0.68258 + 0.00211298\n",
      "[4300]\tcv_agg's multi_logloss: 0.681766 + 0.00214045\n",
      "[4320]\tcv_agg's multi_logloss: 0.680893 + 0.00211028\n",
      "[4340]\tcv_agg's multi_logloss: 0.680105 + 0.00212376\n",
      "[4360]\tcv_agg's multi_logloss: 0.679304 + 0.00213767\n",
      "[4380]\tcv_agg's multi_logloss: 0.678498 + 0.00211907\n",
      "[4400]\tcv_agg's multi_logloss: 0.677682 + 0.00212438\n",
      "[4420]\tcv_agg's multi_logloss: 0.676868 + 0.00215934\n",
      "[4440]\tcv_agg's multi_logloss: 0.676134 + 0.00218655\n",
      "[4460]\tcv_agg's multi_logloss: 0.67533 + 0.00214876\n",
      "[4480]\tcv_agg's multi_logloss: 0.674528 + 0.00212222\n",
      "[4500]\tcv_agg's multi_logloss: 0.67377 + 0.00208797\n",
      "[4520]\tcv_agg's multi_logloss: 0.673006 + 0.00209339\n",
      "[4540]\tcv_agg's multi_logloss: 0.6722 + 0.00211909\n",
      "[4560]\tcv_agg's multi_logloss: 0.671409 + 0.00214807\n",
      "[4580]\tcv_agg's multi_logloss: 0.670642 + 0.00217106\n",
      "[4600]\tcv_agg's multi_logloss: 0.669848 + 0.002159\n",
      "[4620]\tcv_agg's multi_logloss: 0.669136 + 0.00217169\n",
      "[4640]\tcv_agg's multi_logloss: 0.668366 + 0.00217599\n",
      "[4660]\tcv_agg's multi_logloss: 0.66764 + 0.00221345\n",
      "[4680]\tcv_agg's multi_logloss: 0.666855 + 0.00218925\n",
      "[4700]\tcv_agg's multi_logloss: 0.666105 + 0.00221418\n",
      "[4720]\tcv_agg's multi_logloss: 0.66538 + 0.00220158\n",
      "[4740]\tcv_agg's multi_logloss: 0.664652 + 0.00219874\n",
      "[4760]\tcv_agg's multi_logloss: 0.663867 + 0.00218918\n",
      "[4780]\tcv_agg's multi_logloss: 0.663177 + 0.00221577\n",
      "[4800]\tcv_agg's multi_logloss: 0.662462 + 0.00219506\n",
      "[4820]\tcv_agg's multi_logloss: 0.661724 + 0.00215963\n",
      "[4840]\tcv_agg's multi_logloss: 0.661038 + 0.00215556\n",
      "[4860]\tcv_agg's multi_logloss: 0.660308 + 0.00216928\n",
      "[4880]\tcv_agg's multi_logloss: 0.659586 + 0.00210599\n",
      "[4900]\tcv_agg's multi_logloss: 0.658851 + 0.00213808\n",
      "[4920]\tcv_agg's multi_logloss: 0.65813 + 0.00215386\n",
      "[4940]\tcv_agg's multi_logloss: 0.657425 + 0.0021662\n",
      "[4960]\tcv_agg's multi_logloss: 0.656704 + 0.00213296\n",
      "[4980]\tcv_agg's multi_logloss: 0.655987 + 0.0021391\n",
      "[5000]\tcv_agg's multi_logloss: 0.655297 + 0.00210013\n",
      "[5020]\tcv_agg's multi_logloss: 0.654627 + 0.00212817\n",
      "[5040]\tcv_agg's multi_logloss: 0.653966 + 0.00212462\n",
      "[5060]\tcv_agg's multi_logloss: 0.653277 + 0.00213943\n",
      "[5080]\tcv_agg's multi_logloss: 0.652575 + 0.00213939\n",
      "[5100]\tcv_agg's multi_logloss: 0.651866 + 0.00209909\n",
      "[5120]\tcv_agg's multi_logloss: 0.65119 + 0.00213024\n",
      "[5140]\tcv_agg's multi_logloss: 0.650532 + 0.0021235\n",
      "[5160]\tcv_agg's multi_logloss: 0.649856 + 0.00211886\n",
      "[5180]\tcv_agg's multi_logloss: 0.64919 + 0.00210443\n",
      "[5200]\tcv_agg's multi_logloss: 0.648522 + 0.00210592\n",
      "[5220]\tcv_agg's multi_logloss: 0.647846 + 0.00211881\n",
      "[5240]\tcv_agg's multi_logloss: 0.647221 + 0.0021184\n",
      "[5260]\tcv_agg's multi_logloss: 0.646621 + 0.00214185\n",
      "[5280]\tcv_agg's multi_logloss: 0.645973 + 0.00216031\n",
      "[5300]\tcv_agg's multi_logloss: 0.645341 + 0.00213931\n",
      "[5320]\tcv_agg's multi_logloss: 0.644721 + 0.00212583\n",
      "[5340]\tcv_agg's multi_logloss: 0.644098 + 0.00211719\n",
      "[5360]\tcv_agg's multi_logloss: 0.643484 + 0.00206007\n",
      "[5380]\tcv_agg's multi_logloss: 0.642849 + 0.00206739\n",
      "[5400]\tcv_agg's multi_logloss: 0.642221 + 0.00205118\n",
      "[5420]\tcv_agg's multi_logloss: 0.641584 + 0.00204799\n",
      "[5440]\tcv_agg's multi_logloss: 0.640952 + 0.00203983\n",
      "[5460]\tcv_agg's multi_logloss: 0.640332 + 0.00203268\n",
      "[5480]\tcv_agg's multi_logloss: 0.639718 + 0.00205203\n",
      "[5500]\tcv_agg's multi_logloss: 0.639105 + 0.00206002\n",
      "[5520]\tcv_agg's multi_logloss: 0.638453 + 0.00205402\n",
      "[5540]\tcv_agg's multi_logloss: 0.637842 + 0.00209502\n",
      "[5560]\tcv_agg's multi_logloss: 0.637272 + 0.00205618\n",
      "[5580]\tcv_agg's multi_logloss: 0.636662 + 0.00206112\n",
      "[5600]\tcv_agg's multi_logloss: 0.63605 + 0.00209985\n",
      "[5620]\tcv_agg's multi_logloss: 0.635457 + 0.00211377\n",
      "[5640]\tcv_agg's multi_logloss: 0.634821 + 0.00207467\n",
      "[5660]\tcv_agg's multi_logloss: 0.634234 + 0.00208387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5680]\tcv_agg's multi_logloss: 0.633647 + 0.00211947\n",
      "[5700]\tcv_agg's multi_logloss: 0.63307 + 0.00206396\n",
      "[5720]\tcv_agg's multi_logloss: 0.63248 + 0.0020671\n",
      "[5740]\tcv_agg's multi_logloss: 0.631903 + 0.00209612\n",
      "[5760]\tcv_agg's multi_logloss: 0.631331 + 0.00210364\n",
      "[5780]\tcv_agg's multi_logloss: 0.630748 + 0.00209853\n",
      "[5800]\tcv_agg's multi_logloss: 0.630174 + 0.00209629\n",
      "[5820]\tcv_agg's multi_logloss: 0.629577 + 0.00211292\n",
      "[5840]\tcv_agg's multi_logloss: 0.629017 + 0.00212045\n",
      "[5860]\tcv_agg's multi_logloss: 0.628482 + 0.00209819\n",
      "[5880]\tcv_agg's multi_logloss: 0.627939 + 0.00209754\n",
      "[5900]\tcv_agg's multi_logloss: 0.627423 + 0.0021263\n",
      "[5920]\tcv_agg's multi_logloss: 0.626883 + 0.0021174\n",
      "[5940]\tcv_agg's multi_logloss: 0.626317 + 0.00213248\n",
      "[5960]\tcv_agg's multi_logloss: 0.62581 + 0.00215566\n",
      "[5980]\tcv_agg's multi_logloss: 0.625268 + 0.00216628\n",
      "[6000]\tcv_agg's multi_logloss: 0.624778 + 0.00217055\n",
      "[6020]\tcv_agg's multi_logloss: 0.624231 + 0.00213238\n",
      "[6040]\tcv_agg's multi_logloss: 0.623693 + 0.00210449\n",
      "[6060]\tcv_agg's multi_logloss: 0.623178 + 0.002076\n",
      "[6080]\tcv_agg's multi_logloss: 0.622644 + 0.0020596\n",
      "[6100]\tcv_agg's multi_logloss: 0.62211 + 0.00209759\n",
      "[6120]\tcv_agg's multi_logloss: 0.621547 + 0.002103\n",
      "[6140]\tcv_agg's multi_logloss: 0.62107 + 0.00212361\n",
      "[6160]\tcv_agg's multi_logloss: 0.620557 + 0.00213507\n",
      "[6180]\tcv_agg's multi_logloss: 0.620059 + 0.00213729\n",
      "[6200]\tcv_agg's multi_logloss: 0.619565 + 0.00216653\n",
      "[6220]\tcv_agg's multi_logloss: 0.619043 + 0.00217946\n",
      "[6240]\tcv_agg's multi_logloss: 0.618489 + 0.00213522\n",
      "[6260]\tcv_agg's multi_logloss: 0.617938 + 0.00210233\n",
      "[6280]\tcv_agg's multi_logloss: 0.617401 + 0.00211\n",
      "[6300]\tcv_agg's multi_logloss: 0.616891 + 0.00212759\n",
      "[6320]\tcv_agg's multi_logloss: 0.61641 + 0.00210777\n",
      "[6340]\tcv_agg's multi_logloss: 0.615926 + 0.00211647\n",
      "[6360]\tcv_agg's multi_logloss: 0.615415 + 0.00208137\n",
      "[6380]\tcv_agg's multi_logloss: 0.614915 + 0.00208915\n",
      "[6400]\tcv_agg's multi_logloss: 0.61444 + 0.00209358\n",
      "[6420]\tcv_agg's multi_logloss: 0.613978 + 0.00208455\n",
      "[6440]\tcv_agg's multi_logloss: 0.613487 + 0.00206316\n",
      "[6460]\tcv_agg's multi_logloss: 0.613024 + 0.00206814\n",
      "[6480]\tcv_agg's multi_logloss: 0.61251 + 0.00204444\n",
      "[6500]\tcv_agg's multi_logloss: 0.612011 + 0.00203689\n",
      "[6520]\tcv_agg's multi_logloss: 0.611544 + 0.00201859\n",
      "[6540]\tcv_agg's multi_logloss: 0.611054 + 0.002031\n",
      "[6560]\tcv_agg's multi_logloss: 0.610562 + 0.00202306\n",
      "[6580]\tcv_agg's multi_logloss: 0.610075 + 0.00199269\n",
      "[6600]\tcv_agg's multi_logloss: 0.609631 + 0.00200044\n",
      "[6620]\tcv_agg's multi_logloss: 0.609146 + 0.00201416\n",
      "[6640]\tcv_agg's multi_logloss: 0.608672 + 0.00202795\n",
      "[6660]\tcv_agg's multi_logloss: 0.608257 + 0.00203882\n",
      "[6680]\tcv_agg's multi_logloss: 0.607843 + 0.00205343\n",
      "[6700]\tcv_agg's multi_logloss: 0.607386 + 0.00206514\n",
      "[6720]\tcv_agg's multi_logloss: 0.606928 + 0.00202617\n",
      "[6740]\tcv_agg's multi_logloss: 0.606486 + 0.00202192\n",
      "[6760]\tcv_agg's multi_logloss: 0.606007 + 0.0020123\n",
      "[6780]\tcv_agg's multi_logloss: 0.605566 + 0.00200432\n",
      "[6800]\tcv_agg's multi_logloss: 0.60515 + 0.00198195\n",
      "[6820]\tcv_agg's multi_logloss: 0.60467 + 0.00200003\n",
      "[6840]\tcv_agg's multi_logloss: 0.604212 + 0.00199809\n",
      "[6860]\tcv_agg's multi_logloss: 0.603753 + 0.00205767\n",
      "[6880]\tcv_agg's multi_logloss: 0.603278 + 0.00206823\n",
      "[6900]\tcv_agg's multi_logloss: 0.602854 + 0.00209771\n",
      "[6920]\tcv_agg's multi_logloss: 0.602441 + 0.00208581\n",
      "[6940]\tcv_agg's multi_logloss: 0.602032 + 0.00208523\n",
      "[6960]\tcv_agg's multi_logloss: 0.601616 + 0.00211124\n",
      "[6980]\tcv_agg's multi_logloss: 0.601165 + 0.00209709\n",
      "[7000]\tcv_agg's multi_logloss: 0.600766 + 0.0021113\n",
      "[7020]\tcv_agg's multi_logloss: 0.600352 + 0.00212158\n",
      "[7040]\tcv_agg's multi_logloss: 0.599922 + 0.00210924\n",
      "[7060]\tcv_agg's multi_logloss: 0.599476 + 0.00208462\n",
      "[7080]\tcv_agg's multi_logloss: 0.599048 + 0.00207437\n",
      "[7100]\tcv_agg's multi_logloss: 0.598625 + 0.00207393\n",
      "[7120]\tcv_agg's multi_logloss: 0.598166 + 0.00208004\n",
      "[7140]\tcv_agg's multi_logloss: 0.597696 + 0.00207367\n",
      "[7160]\tcv_agg's multi_logloss: 0.59728 + 0.00210589\n",
      "[7180]\tcv_agg's multi_logloss: 0.596856 + 0.00211188\n",
      "[7200]\tcv_agg's multi_logloss: 0.596466 + 0.00210543\n",
      "[7220]\tcv_agg's multi_logloss: 0.596094 + 0.0021061\n",
      "[7240]\tcv_agg's multi_logloss: 0.595717 + 0.00210553\n",
      "[7260]\tcv_agg's multi_logloss: 0.595329 + 0.00208202\n",
      "[7280]\tcv_agg's multi_logloss: 0.594933 + 0.00205649\n",
      "[7300]\tcv_agg's multi_logloss: 0.594552 + 0.00205265\n",
      "[7320]\tcv_agg's multi_logloss: 0.594158 + 0.00204333\n",
      "[7340]\tcv_agg's multi_logloss: 0.593801 + 0.0020505\n",
      "[7360]\tcv_agg's multi_logloss: 0.593412 + 0.00205008\n",
      "[7380]\tcv_agg's multi_logloss: 0.593002 + 0.00203941\n",
      "[7400]\tcv_agg's multi_logloss: 0.592594 + 0.00203056\n",
      "[7420]\tcv_agg's multi_logloss: 0.592211 + 0.0020334\n",
      "[7440]\tcv_agg's multi_logloss: 0.591832 + 0.00206311\n",
      "[7460]\tcv_agg's multi_logloss: 0.591447 + 0.00203992\n",
      "[7480]\tcv_agg's multi_logloss: 0.591033 + 0.00203187\n",
      "[7500]\tcv_agg's multi_logloss: 0.590681 + 0.00203301\n",
      "[7520]\tcv_agg's multi_logloss: 0.590283 + 0.00201591\n",
      "[7540]\tcv_agg's multi_logloss: 0.589899 + 0.0020096\n",
      "[7560]\tcv_agg's multi_logloss: 0.589546 + 0.00203637\n",
      "[7580]\tcv_agg's multi_logloss: 0.589188 + 0.00203942\n",
      "[7600]\tcv_agg's multi_logloss: 0.588811 + 0.00205127\n",
      "[7620]\tcv_agg's multi_logloss: 0.588436 + 0.00207165\n",
      "[7640]\tcv_agg's multi_logloss: 0.588038 + 0.00209292\n",
      "[7660]\tcv_agg's multi_logloss: 0.587666 + 0.00207771\n",
      "[7680]\tcv_agg's multi_logloss: 0.587288 + 0.00204089\n",
      "[7700]\tcv_agg's multi_logloss: 0.586926 + 0.00203239\n",
      "[7720]\tcv_agg's multi_logloss: 0.586543 + 0.00204894\n",
      "[7740]\tcv_agg's multi_logloss: 0.586184 + 0.00206209\n",
      "[7760]\tcv_agg's multi_logloss: 0.585835 + 0.00207656\n",
      "[7780]\tcv_agg's multi_logloss: 0.585498 + 0.00209321\n",
      "[7800]\tcv_agg's multi_logloss: 0.585147 + 0.00212351\n",
      "[7820]\tcv_agg's multi_logloss: 0.584815 + 0.00208473\n",
      "[7840]\tcv_agg's multi_logloss: 0.584476 + 0.00209472\n",
      "[7860]\tcv_agg's multi_logloss: 0.584089 + 0.00207904\n",
      "[7880]\tcv_agg's multi_logloss: 0.583734 + 0.00208837\n",
      "[7900]\tcv_agg's multi_logloss: 0.58341 + 0.00208252\n",
      "[7920]\tcv_agg's multi_logloss: 0.583089 + 0.00205782\n",
      "[7940]\tcv_agg's multi_logloss: 0.58273 + 0.00205407\n",
      "[7960]\tcv_agg's multi_logloss: 0.582386 + 0.00206601\n",
      "[7980]\tcv_agg's multi_logloss: 0.582027 + 0.00208997\n",
      "[8000]\tcv_agg's multi_logloss: 0.581652 + 0.00208338\n",
      "[8020]\tcv_agg's multi_logloss: 0.581295 + 0.00206012\n",
      "[8040]\tcv_agg's multi_logloss: 0.580944 + 0.00207804\n",
      "[8060]\tcv_agg's multi_logloss: 0.580588 + 0.00204162\n",
      "[8080]\tcv_agg's multi_logloss: 0.58025 + 0.00201935\n",
      "[8100]\tcv_agg's multi_logloss: 0.579931 + 0.00203758\n",
      "[8120]\tcv_agg's multi_logloss: 0.579608 + 0.00205859\n",
      "[8140]\tcv_agg's multi_logloss: 0.579286 + 0.00208721\n",
      "[8160]\tcv_agg's multi_logloss: 0.578985 + 0.00209072\n",
      "[8180]\tcv_agg's multi_logloss: 0.578657 + 0.00208634\n",
      "[8200]\tcv_agg's multi_logloss: 0.578327 + 0.00209718\n",
      "[8220]\tcv_agg's multi_logloss: 0.578052 + 0.00210699\n",
      "[8240]\tcv_agg's multi_logloss: 0.577743 + 0.00209404\n",
      "[8260]\tcv_agg's multi_logloss: 0.577469 + 0.00209797\n",
      "[8280]\tcv_agg's multi_logloss: 0.577119 + 0.00213447\n",
      "[8300]\tcv_agg's multi_logloss: 0.57677 + 0.00215056\n",
      "[8320]\tcv_agg's multi_logloss: 0.57645 + 0.00213845\n",
      "[8340]\tcv_agg's multi_logloss: 0.57614 + 0.00211051\n",
      "[8360]\tcv_agg's multi_logloss: 0.575836 + 0.0021137\n",
      "[8380]\tcv_agg's multi_logloss: 0.575525 + 0.00208502\n",
      "[8400]\tcv_agg's multi_logloss: 0.575199 + 0.00211368\n",
      "[8420]\tcv_agg's multi_logloss: 0.574892 + 0.00211529\n",
      "[8440]\tcv_agg's multi_logloss: 0.574572 + 0.00213191\n",
      "[8460]\tcv_agg's multi_logloss: 0.574241 + 0.0021434\n",
      "[8480]\tcv_agg's multi_logloss: 0.573958 + 0.00214757\n",
      "[8500]\tcv_agg's multi_logloss: 0.573644 + 0.00215775\n",
      "[8520]\tcv_agg's multi_logloss: 0.573344 + 0.00216592\n",
      "[8540]\tcv_agg's multi_logloss: 0.573045 + 0.00214044\n",
      "[8560]\tcv_agg's multi_logloss: 0.572707 + 0.00214188\n",
      "[8580]\tcv_agg's multi_logloss: 0.572415 + 0.00216125\n",
      "[8600]\tcv_agg's multi_logloss: 0.572084 + 0.00214625\n",
      "[8620]\tcv_agg's multi_logloss: 0.571799 + 0.00213523\n",
      "[8640]\tcv_agg's multi_logloss: 0.571528 + 0.00213591\n",
      "[8660]\tcv_agg's multi_logloss: 0.571218 + 0.00213307\n",
      "[8680]\tcv_agg's multi_logloss: 0.57093 + 0.00212358\n",
      "[8700]\tcv_agg's multi_logloss: 0.570644 + 0.00213679\n",
      "[8720]\tcv_agg's multi_logloss: 0.570382 + 0.0021618\n",
      "[8740]\tcv_agg's multi_logloss: 0.570115 + 0.00218563\n",
      "[8760]\tcv_agg's multi_logloss: 0.569803 + 0.00219411\n",
      "[8780]\tcv_agg's multi_logloss: 0.569518 + 0.00220904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8800]\tcv_agg's multi_logloss: 0.569231 + 0.00221083\n",
      "[8820]\tcv_agg's multi_logloss: 0.568944 + 0.0022201\n",
      "[8840]\tcv_agg's multi_logloss: 0.568641 + 0.00220242\n",
      "[8860]\tcv_agg's multi_logloss: 0.56839 + 0.00216959\n",
      "[8880]\tcv_agg's multi_logloss: 0.568129 + 0.0021736\n",
      "[8900]\tcv_agg's multi_logloss: 0.567887 + 0.0021799\n",
      "[8920]\tcv_agg's multi_logloss: 0.567602 + 0.0021739\n",
      "[8940]\tcv_agg's multi_logloss: 0.567315 + 0.00215148\n",
      "[8960]\tcv_agg's multi_logloss: 0.567028 + 0.00215469\n",
      "[8980]\tcv_agg's multi_logloss: 0.566782 + 0.00215274\n",
      "[9000]\tcv_agg's multi_logloss: 0.56649 + 0.00213346\n",
      "[9020]\tcv_agg's multi_logloss: 0.566209 + 0.00214549\n",
      "[9040]\tcv_agg's multi_logloss: 0.565938 + 0.00214283\n",
      "[9060]\tcv_agg's multi_logloss: 0.565696 + 0.00213233\n",
      "[9080]\tcv_agg's multi_logloss: 0.565405 + 0.00212494\n",
      "[9100]\tcv_agg's multi_logloss: 0.565115 + 0.00214434\n",
      "[9120]\tcv_agg's multi_logloss: 0.564834 + 0.0021982\n",
      "[9140]\tcv_agg's multi_logloss: 0.56456 + 0.00219128\n",
      "[9160]\tcv_agg's multi_logloss: 0.564328 + 0.00213381\n",
      "[9180]\tcv_agg's multi_logloss: 0.564053 + 0.00209434\n",
      "[9200]\tcv_agg's multi_logloss: 0.56378 + 0.00209239\n",
      "[9220]\tcv_agg's multi_logloss: 0.563539 + 0.00206457\n",
      "[9240]\tcv_agg's multi_logloss: 0.563326 + 0.00204566\n",
      "[9260]\tcv_agg's multi_logloss: 0.563092 + 0.0020568\n",
      "[9280]\tcv_agg's multi_logloss: 0.562817 + 0.00207514\n",
      "[9300]\tcv_agg's multi_logloss: 0.562521 + 0.00205771\n",
      "[9320]\tcv_agg's multi_logloss: 0.562283 + 0.0020772\n",
      "[9340]\tcv_agg's multi_logloss: 0.562035 + 0.00210327\n",
      "[9360]\tcv_agg's multi_logloss: 0.56179 + 0.002119\n",
      "[9380]\tcv_agg's multi_logloss: 0.561543 + 0.00214815\n",
      "[9400]\tcv_agg's multi_logloss: 0.561304 + 0.00214885\n",
      "[9420]\tcv_agg's multi_logloss: 0.561008 + 0.00212116\n",
      "[9440]\tcv_agg's multi_logloss: 0.560776 + 0.00210529\n",
      "[9460]\tcv_agg's multi_logloss: 0.560553 + 0.00211242\n",
      "[9480]\tcv_agg's multi_logloss: 0.560318 + 0.00210946\n",
      "[9500]\tcv_agg's multi_logloss: 0.560061 + 0.00208521\n",
      "[9520]\tcv_agg's multi_logloss: 0.559813 + 0.00213903\n",
      "[9540]\tcv_agg's multi_logloss: 0.559586 + 0.00214096\n",
      "[9560]\tcv_agg's multi_logloss: 0.55932 + 0.00217437\n",
      "[9580]\tcv_agg's multi_logloss: 0.559089 + 0.00220355\n",
      "[9600]\tcv_agg's multi_logloss: 0.558854 + 0.00221631\n",
      "[9620]\tcv_agg's multi_logloss: 0.558592 + 0.00225131\n",
      "[9640]\tcv_agg's multi_logloss: 0.55834 + 0.00223699\n",
      "[9660]\tcv_agg's multi_logloss: 0.558106 + 0.00221821\n",
      "[9680]\tcv_agg's multi_logloss: 0.557869 + 0.00222246\n",
      "[9700]\tcv_agg's multi_logloss: 0.557709 + 0.00218424\n",
      "[9720]\tcv_agg's multi_logloss: 0.557488 + 0.00214805\n",
      "[9740]\tcv_agg's multi_logloss: 0.557248 + 0.00217526\n",
      "[9760]\tcv_agg's multi_logloss: 0.557007 + 0.00217178\n",
      "[9780]\tcv_agg's multi_logloss: 0.556766 + 0.00216622\n",
      "[9800]\tcv_agg's multi_logloss: 0.556566 + 0.00215962\n",
      "[9820]\tcv_agg's multi_logloss: 0.556318 + 0.00216211\n",
      "[9840]\tcv_agg's multi_logloss: 0.556049 + 0.00214812\n",
      "[9860]\tcv_agg's multi_logloss: 0.555802 + 0.00215111\n",
      "[9880]\tcv_agg's multi_logloss: 0.555564 + 0.00212458\n",
      "[9900]\tcv_agg's multi_logloss: 0.555347 + 0.00214474\n",
      "[9920]\tcv_agg's multi_logloss: 0.555109 + 0.00217267\n",
      "[9940]\tcv_agg's multi_logloss: 0.554856 + 0.00215994\n",
      "[9960]\tcv_agg's multi_logloss: 0.55462 + 0.00214458\n",
      "[9980]\tcv_agg's multi_logloss: 0.554415 + 0.00216257\n",
      "[10000]\tcv_agg's multi_logloss: 0.554131 + 0.00218711\n",
      "9999\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 101529, number of used features: 1000\n",
      "[LightGBM] [Info] Start training from score -0.648846\n",
      "[LightGBM] [Info] Start training from score -2.080950\n",
      "[LightGBM] [Info] Start training from score -2.050867\n",
      "[LightGBM] [Info] Start training from score -1.496483\n"
     ]
    }
   ],
   "source": [
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':4,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 17,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 17}\n",
    "d_train = lgb.Dataset(augmentation_train_x, label=augmentation_train_y)\n",
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=10000, nfold=3, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=100)\n",
    "\n",
    "nround = lgb_cv['multi_logloss-mean'].index(np.min(lgb_cv['multi_logloss-mean']))\n",
    "print(nround)\n",
    "\n",
    "model = lgb.train(params, d_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b89d50f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60195107 0.06516317 0.02862592 0.30425983]\n",
      " [0.54760456 0.0797097  0.0966598  0.27602595]\n",
      " [0.80450448 0.02101062 0.0607405  0.1137444 ]\n",
      " ...\n",
      " [0.70875599 0.03968137 0.06667306 0.18488957]\n",
      " [0.5687513  0.11274975 0.01997947 0.29851948]\n",
      " [0.55354164 0.12368433 0.09819259 0.22458144]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_x)\n",
    "print(preds) \n",
    "tmp = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3340c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59358841778697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_set_y,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "730c69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2793  390 1070  109]\n",
      " [  54   62   20   38]\n",
      " [   9    0    0    0]\n",
      " [ 223   22   30   15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "NN_confusion_matrix = confusion_matrix(test_set_y, tmp).T\n",
    "print(NN_confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
