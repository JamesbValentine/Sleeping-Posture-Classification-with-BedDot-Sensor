{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from skimage.measure import block_reduce \n",
    "from keras.models import load_model,Model,Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Activation\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "    \n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator for training set\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "# data generator for test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7785 images belonging to 102 classes.\n",
      "Found 1359 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "steps_per_epoch=np.ceil(7785/batch_size)\n",
    "validation_steps=np.ceil(1359/batch_size)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/101_ObjectCategories',\n",
    "    target_size = (299, 299),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (299, 299),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####create model\n",
    "def base_model(name):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (299,299,3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.get_layer(name).output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    predictions = Dense(102, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 102)          208998      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,011,782\n",
      "Trainable params: 208,998\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 959s 4s/step - loss: 1.7510 - acc: 0.6451 - val_loss: 0.5778 - val_acc: 0.8624\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.5062 - acc: 0.8760 - val_loss: 0.4001 - val_acc: 0.9058\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.3464 - acc: 0.9089 - val_loss: 0.3580 - val_acc: 0.9029\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.2662 - acc: 0.9257 - val_loss: 0.3406 - val_acc: 0.8999\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.2216 - acc: 0.9347 - val_loss: 0.3248 - val_acc: 0.9080\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.1906 - acc: 0.9445 - val_loss: 0.3246 - val_acc: 0.9117\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.1608 - acc: 0.9537 - val_loss: 0.3212 - val_acc: 0.9095\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 0.1346 - acc: 0.9641 - val_loss: 0.3387 - val_acc: 0.9088\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.1351 - acc: 0.9605 - val_loss: 0.3351 - val_acc: 0.9102\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.1185 - acc: 0.9652 - val_loss: 0.2910 - val_acc: 0.9220\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.1113 - acc: 0.9696 - val_loss: 0.2972 - val_acc: 0.9146\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.1078 - acc: 0.9705 - val_loss: 0.2962 - val_acc: 0.9088\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0912 - acc: 0.9737 - val_loss: 0.3261 - val_acc: 0.9029\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 120s 493ms/step - loss: 0.0859 - acc: 0.9769 - val_loss: 0.3206 - val_acc: 0.9080\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 85s 348ms/step - loss: 0.0835 - acc: 0.9745 - val_loss: 0.2944 - val_acc: 0.9154\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0907 - acc: 0.9706 - val_loss: 0.3683 - val_acc: 0.8918\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0823 - acc: 0.9754 - val_loss: 0.3067 - val_acc: 0.9161\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 0.0723 - acc: 0.9780 - val_loss: 0.3219 - val_acc: 0.9169\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 0.0764 - acc: 0.9755 - val_loss: 0.3624 - val_acc: 0.9051\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0779 - acc: 0.9776 - val_loss: 0.3367 - val_acc: 0.9080\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0727 - acc: 0.9778 - val_loss: 0.3352 - val_acc: 0.9110\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0645 - acc: 0.9792 - val_loss: 0.3391 - val_acc: 0.9132\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0714 - acc: 0.9780 - val_loss: 0.3021 - val_acc: 0.9191\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0649 - acc: 0.9793 - val_loss: 0.3533 - val_acc: 0.9051\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0628 - acc: 0.9803 - val_loss: 0.3398 - val_acc: 0.9036\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0660 - acc: 0.9804 - val_loss: 0.3808 - val_acc: 0.9029\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 0.0630 - acc: 0.9789 - val_loss: 0.3296 - val_acc: 0.9154\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0556 - acc: 0.9821 - val_loss: 0.3172 - val_acc: 0.9183\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0559 - acc: 0.9816 - val_loss: 0.3335 - val_acc: 0.9169\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0616 - acc: 0.9793 - val_loss: 0.3074 - val_acc: 0.9220\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0606 - acc: 0.9815 - val_loss: 0.4351 - val_acc: 0.8845\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.0566 - acc: 0.9822 - val_loss: 0.3146 - val_acc: 0.9154\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0590 - acc: 0.9782 - val_loss: 0.3525 - val_acc: 0.9176\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0576 - acc: 0.9807 - val_loss: 0.3732 - val_acc: 0.9021\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0517 - acc: 0.9835 - val_loss: 0.3519 - val_acc: 0.9191\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0502 - acc: 0.9828 - val_loss: 0.3875 - val_acc: 0.9080\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0522 - acc: 0.9810 - val_loss: 0.3810 - val_acc: 0.9102\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.0509 - acc: 0.9825 - val_loss: 0.3701 - val_acc: 0.9110\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0516 - acc: 0.9830 - val_loss: 0.3926 - val_acc: 0.9021\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.0571 - acc: 0.9810 - val_loss: 0.3798 - val_acc: 0.9073\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0491 - acc: 0.9839 - val_loss: 0.3536 - val_acc: 0.9117\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 53s 219ms/step - loss: 0.0396 - acc: 0.9874 - val_loss: 0.3157 - val_acc: 0.9279\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 56s 230ms/step - loss: 0.0493 - acc: 0.9834 - val_loss: 0.3396 - val_acc: 0.9132\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.0516 - acc: 0.9844 - val_loss: 0.3423 - val_acc: 0.9124\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0505 - acc: 0.9836 - val_loss: 0.3567 - val_acc: 0.9198\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.0538 - acc: 0.9814 - val_loss: 0.3938 - val_acc: 0.9051\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.0418 - acc: 0.9858 - val_loss: 0.3635 - val_acc: 0.9183\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0528 - acc: 0.9831 - val_loss: 0.3850 - val_acc: 0.9132\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 0.0441 - acc: 0.9849 - val_loss: 0.3697 - val_acc: 0.9132\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0410 - acc: 0.9873 - val_loss: 0.4075 - val_acc: 0.9146\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0500 - acc: 0.9821 - val_loss: 0.4280 - val_acc: 0.9088\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0483 - acc: 0.9818 - val_loss: 0.3801 - val_acc: 0.9132\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.3923 - val_acc: 0.9110\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0456 - acc: 0.9854 - val_loss: 0.3619 - val_acc: 0.9227\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0397 - acc: 0.9869 - val_loss: 0.4025 - val_acc: 0.9191\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0540 - acc: 0.9823 - val_loss: 0.4217 - val_acc: 0.9124\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0511 - acc: 0.9837 - val_loss: 0.3882 - val_acc: 0.9249\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0385 - acc: 0.9867 - val_loss: 0.4540 - val_acc: 0.9021\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0451 - acc: 0.9844 - val_loss: 0.4131 - val_acc: 0.9132\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0524 - acc: 0.9825 - val_loss: 0.3738 - val_acc: 0.9205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.0440 - acc: 0.9844 - val_loss: 0.3920 - val_acc: 0.9161\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0445 - acc: 0.9848 - val_loss: 0.3981 - val_acc: 0.9176\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0495 - acc: 0.9825 - val_loss: 0.3777 - val_acc: 0.9176\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0403 - acc: 0.9851 - val_loss: 0.3723 - val_acc: 0.9176\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0433 - acc: 0.9878 - val_loss: 0.4369 - val_acc: 0.9029\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0459 - acc: 0.9844 - val_loss: 0.4123 - val_acc: 0.9132\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 58s 238ms/step - loss: 0.0429 - acc: 0.9842 - val_loss: 0.4114 - val_acc: 0.9183\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 54s 219ms/step - loss: 0.0435 - acc: 0.9859 - val_loss: 0.4026 - val_acc: 0.9139\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0399 - acc: 0.9868 - val_loss: 0.3894 - val_acc: 0.9154\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0533 - acc: 0.9836 - val_loss: 0.3714 - val_acc: 0.9213\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0482 - acc: 0.9844 - val_loss: 0.4215 - val_acc: 0.9191\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0487 - acc: 0.9837 - val_loss: 0.4229 - val_acc: 0.9213\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0407 - acc: 0.9858 - val_loss: 0.4012 - val_acc: 0.9139\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0428 - acc: 0.9863 - val_loss: 0.3796 - val_acc: 0.9169\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0377 - acc: 0.9878 - val_loss: 0.4098 - val_acc: 0.9191\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0404 - acc: 0.9862 - val_loss: 0.4104 - val_acc: 0.9264\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0493 - acc: 0.9837 - val_loss: 0.4090 - val_acc: 0.9124\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0346 - acc: 0.9880 - val_loss: 0.4199 - val_acc: 0.9117\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 58s 238ms/step - loss: 0.0396 - acc: 0.9877 - val_loss: 0.4097 - val_acc: 0.9124\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 69s 283ms/step - loss: 0.0441 - acc: 0.9858 - val_loss: 0.4532 - val_acc: 0.9146\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0469 - acc: 0.9848 - val_loss: 0.4142 - val_acc: 0.9161\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0412 - acc: 0.9844 - val_loss: 0.4551 - val_acc: 0.9161\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0402 - acc: 0.9870 - val_loss: 0.4668 - val_acc: 0.9183\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0482 - acc: 0.9851 - val_loss: 0.4320 - val_acc: 0.9124\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0397 - acc: 0.9856 - val_loss: 0.4161 - val_acc: 0.9110\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0423 - acc: 0.9863 - val_loss: 0.3839 - val_acc: 0.9205\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.0333 - acc: 0.9881 - val_loss: 0.3975 - val_acc: 0.9220\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0423 - acc: 0.9841 - val_loss: 0.4544 - val_acc: 0.9073\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0351 - acc: 0.9876 - val_loss: 0.4751 - val_acc: 0.9021\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0494 - acc: 0.9837 - val_loss: 0.4289 - val_acc: 0.9205\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0448 - acc: 0.9848 - val_loss: 0.4233 - val_acc: 0.9242\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0348 - acc: 0.9878 - val_loss: 0.4021 - val_acc: 0.9154\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0487 - acc: 0.9857 - val_loss: 0.4335 - val_acc: 0.9095\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0448 - acc: 0.9849 - val_loss: 0.4486 - val_acc: 0.9080\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0398 - acc: 0.9884 - val_loss: 0.4058 - val_acc: 0.9139\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0375 - acc: 0.9869 - val_loss: 0.4233 - val_acc: 0.9124\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0415 - acc: 0.9862 - val_loss: 0.4935 - val_acc: 0.9065\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 56s 231ms/step - loss: 0.0397 - acc: 0.9855 - val_loss: 0.4460 - val_acc: 0.9183\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 76s 310ms/step - loss: 0.0383 - acc: 0.9876 - val_loss: 0.4879 - val_acc: 0.9065\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0358 - acc: 0.9871 - val_loss: 0.4309 - val_acc: 0.9154\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed10')\n",
    "hist10=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep10acc.txt',hist10.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 149, 149, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 149, 149, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 147, 147, 32) 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 147, 147, 32) 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 147, 147, 32) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 147, 147, 64) 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 147, 147, 64) 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 147, 147, 64) 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 73, 73, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 73, 73, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 71, 71, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 71, 71, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 71, 71, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 35, 35, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 35, 35, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 35, 35, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 35, 35, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 35, 35, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 35, 35, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 35, 35, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 35, 35, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 35, 35, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 35, 35, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 35, 35, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 35, 35, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 35, 35, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 35, 35, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 35, 35, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 35, 35, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 35, 35, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 35, 35, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 35, 35, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 35, 35, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 35, 35, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 35, 35, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 35, 35, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 35, 35, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 35, 35, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 35, 35, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 35, 35, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 35, 35, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 35, 35, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 35, 35, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 35, 35, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 35, 35, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 35, 35, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 35, 35, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 35, 35, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 35, 35, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 35, 35, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 35, 35, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 35, 35, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 35, 35, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 35, 35, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 35, 35, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 96)   82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 384)  1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 96)   288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 384)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 96)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 128)  114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 128)  114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 128)  384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 128)  384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 192)  172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 160)  179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 160)  480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 160)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 192)  215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 192)  576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 192)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 160)  179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 160)  179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 160)  480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 160)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 192)  215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 192)  258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 17, 17, 192)  258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 17, 17, 192)  258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 17, 17, 192)  576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 17, 17, 192)  576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 17, 17, 192)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 17, 17, 192)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 320)    552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 192)    331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 384)    1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 102)          208998      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,931,718\n",
      "Trainable params: 208,998\n",
      "Non-trainable params: 15,722,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 2.6954 - acc: 0.4554 - val_loss: 1.6403 - val_acc: 0.6939\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 1.1929 - acc: 0.8446 - val_loss: 0.9323 - val_acc: 0.8602\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.7175 - acc: 0.9124 - val_loss: 0.6682 - val_acc: 0.8815\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.5122 - acc: 0.9373 - val_loss: 0.5259 - val_acc: 0.8999\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.3865 - acc: 0.9495 - val_loss: 0.4443 - val_acc: 0.9073\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.3122 - acc: 0.9577 - val_loss: 0.4135 - val_acc: 0.9095\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.2603 - acc: 0.9637 - val_loss: 0.3760 - val_acc: 0.9065\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.2185 - acc: 0.9708 - val_loss: 0.3433 - val_acc: 0.9146\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1924 - acc: 0.9754 - val_loss: 0.3229 - val_acc: 0.9161\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.1730 - acc: 0.9763 - val_loss: 0.3142 - val_acc: 0.9154\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.1502 - acc: 0.9816 - val_loss: 0.2889 - val_acc: 0.9235\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.1353 - acc: 0.9830 - val_loss: 0.2810 - val_acc: 0.9242\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.1161 - acc: 0.9885 - val_loss: 0.2635 - val_acc: 0.9316\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.1096 - acc: 0.9867 - val_loss: 0.2608 - val_acc: 0.9264\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0974 - acc: 0.9890 - val_loss: 0.2588 - val_acc: 0.9220\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.0911 - acc: 0.9896 - val_loss: 0.2530 - val_acc: 0.9227\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0820 - acc: 0.9901 - val_loss: 0.2468 - val_acc: 0.9257\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0774 - acc: 0.9910 - val_loss: 0.2458 - val_acc: 0.9257\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.0711 - acc: 0.9922 - val_loss: 0.2364 - val_acc: 0.9308\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.0649 - acc: 0.9935 - val_loss: 0.2253 - val_acc: 0.9345\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0583 - acc: 0.9942 - val_loss: 0.2194 - val_acc: 0.9338\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.0557 - acc: 0.9942 - val_loss: 0.2347 - val_acc: 0.9235\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0503 - acc: 0.9954 - val_loss: 0.2168 - val_acc: 0.9345\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 0.0518 - acc: 0.9932 - val_loss: 0.2391 - val_acc: 0.9220\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 58s 238ms/step - loss: 0.0451 - acc: 0.9946 - val_loss: 0.2058 - val_acc: 0.9360\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 57s 235ms/step - loss: 0.0439 - acc: 0.9964 - val_loss: 0.2228 - val_acc: 0.9323\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0410 - acc: 0.9960 - val_loss: 0.2267 - val_acc: 0.9213\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.0400 - acc: 0.9962 - val_loss: 0.2229 - val_acc: 0.9323\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0376 - acc: 0.9964 - val_loss: 0.2122 - val_acc: 0.9345\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.0347 - acc: 0.9962 - val_loss: 0.2192 - val_acc: 0.9330\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0334 - acc: 0.9967 - val_loss: 0.2152 - val_acc: 0.9360\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0320 - acc: 0.9956 - val_loss: 0.2193 - val_acc: 0.9272\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.0307 - acc: 0.9960 - val_loss: 0.2185 - val_acc: 0.9330\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.0282 - acc: 0.9969 - val_loss: 0.2145 - val_acc: 0.9323\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0269 - acc: 0.9969 - val_loss: 0.2156 - val_acc: 0.9316\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 75s 306ms/step - loss: 0.0257 - acc: 0.9977 - val_loss: 0.2072 - val_acc: 0.9404\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0235 - acc: 0.9974 - val_loss: 0.2221 - val_acc: 0.9330\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.0233 - acc: 0.9980 - val_loss: 0.2022 - val_acc: 0.9375\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 56s 229ms/step - loss: 0.0221 - acc: 0.9976 - val_loss: 0.2223 - val_acc: 0.9235\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 99s 404ms/step - loss: 0.0223 - acc: 0.9980 - val_loss: 0.2209 - val_acc: 0.9294\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0205 - acc: 0.9983 - val_loss: 0.2082 - val_acc: 0.9330\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0219 - acc: 0.9969 - val_loss: 0.2014 - val_acc: 0.9411\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0210 - acc: 0.9977 - val_loss: 0.2060 - val_acc: 0.9323\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.0189 - acc: 0.9976 - val_loss: 0.2165 - val_acc: 0.9308\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.0179 - acc: 0.9968 - val_loss: 0.2157 - val_acc: 0.9323\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0182 - acc: 0.9972 - val_loss: 0.2105 - val_acc: 0.9316\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.0173 - acc: 0.9981 - val_loss: 0.2100 - val_acc: 0.9308\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0168 - acc: 0.9979 - val_loss: 0.2007 - val_acc: 0.9389\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.0161 - acc: 0.9981 - val_loss: 0.2234 - val_acc: 0.9249\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0159 - acc: 0.9982 - val_loss: 0.2221 - val_acc: 0.9323\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0151 - acc: 0.9981 - val_loss: 0.2145 - val_acc: 0.9323\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0160 - acc: 0.9973 - val_loss: 0.2277 - val_acc: 0.9242\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0156 - acc: 0.9976 - val_loss: 0.2120 - val_acc: 0.9367\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0140 - acc: 0.9985 - val_loss: 0.2148 - val_acc: 0.9352\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0129 - acc: 0.9983 - val_loss: 0.2060 - val_acc: 0.9330\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.0128 - acc: 0.9990 - val_loss: 0.2163 - val_acc: 0.9345\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0127 - acc: 0.9985 - val_loss: 0.2013 - val_acc: 0.9338\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0122 - acc: 0.9983 - val_loss: 0.2207 - val_acc: 0.9338\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0116 - acc: 0.9983 - val_loss: 0.2146 - val_acc: 0.9367\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0146 - acc: 0.9977 - val_loss: 0.2100 - val_acc: 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0120 - acc: 0.9986 - val_loss: 0.2137 - val_acc: 0.9330\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0113 - acc: 0.9987 - val_loss: 0.2172 - val_acc: 0.9382\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0104 - acc: 0.9994 - val_loss: 0.2140 - val_acc: 0.9323\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0120 - acc: 0.9980 - val_loss: 0.2280 - val_acc: 0.9227\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0110 - acc: 0.9987 - val_loss: 0.2219 - val_acc: 0.9338\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0100 - acc: 0.9987 - val_loss: 0.2085 - val_acc: 0.9352\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0100 - acc: 0.9986 - val_loss: 0.2040 - val_acc: 0.9352\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.2375 - val_acc: 0.9242\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 57s 235ms/step - loss: 0.0105 - acc: 0.9985 - val_loss: 0.2048 - val_acc: 0.9382\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.0112 - acc: 0.9978 - val_loss: 0.2372 - val_acc: 0.9264\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0096 - acc: 0.9986 - val_loss: 0.2419 - val_acc: 0.9242\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0088 - acc: 0.9988 - val_loss: 0.2285 - val_acc: 0.9338\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.0096 - acc: 0.9988 - val_loss: 0.2298 - val_acc: 0.9294\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0090 - acc: 0.9990 - val_loss: 0.2213 - val_acc: 0.9375\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.2151 - val_acc: 0.9345\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.2224 - val_acc: 0.9367\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.2012 - val_acc: 0.9404\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.2272 - val_acc: 0.9330\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0088 - acc: 0.9987 - val_loss: 0.2089 - val_acc: 0.9397\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.2312 - val_acc: 0.9286\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0092 - acc: 0.9984 - val_loss: 0.2216 - val_acc: 0.9397\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 58s 238ms/step - loss: 0.0074 - acc: 0.9990 - val_loss: 0.2279 - val_acc: 0.9345\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.0082 - acc: 0.9994 - val_loss: 0.2421 - val_acc: 0.9242\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.2098 - val_acc: 0.9316\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 72s 297ms/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.2224 - val_acc: 0.9338\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 328s 1s/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.2463 - val_acc: 0.9220\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 122s 498ms/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.2373 - val_acc: 0.9272\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0070 - acc: 0.9991 - val_loss: 0.2046 - val_acc: 0.9352\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.2316 - val_acc: 0.9286\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.2112 - val_acc: 0.9375\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0080 - acc: 0.9985 - val_loss: 0.2206 - val_acc: 0.9345\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0070 - acc: 0.9985 - val_loss: 0.2287 - val_acc: 0.9308\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0063 - acc: 0.9994 - val_loss: 0.2377 - val_acc: 0.9308\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.2425 - val_acc: 0.9279\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.2332 - val_acc: 0.9330\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.2432 - val_acc: 0.9249\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0073 - acc: 0.9991 - val_loss: 0.2578 - val_acc: 0.9213\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2408 - val_acc: 0.9316\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.2197 - val_acc: 0.9345\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.2339 - val_acc: 0.9352\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed9')\n",
    "hist9=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep9acc.txt',hist9.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 149, 149, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 149, 149, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 149, 149, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 147, 147, 32) 9216        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 147, 147, 32) 96          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 147, 147, 32) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 147, 147, 64) 18432       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 147, 147, 64) 192         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 147, 147, 64) 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 73, 73, 80)   240         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 73, 73, 80)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 71, 71, 192)  138240      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 71, 71, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 71, 71, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 35, 35, 192)  0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 35, 35, 64)   192         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 35, 35, 64)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 35, 35, 96)   55296       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 35, 35, 48)   144         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 35, 35, 48)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 35, 35, 64)   76800       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 35, 35, 96)   82944       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 35, 35, 64)   192         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 35, 35, 96)   288         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 35, 35, 32)   96          conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 35, 35, 64)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 35, 35, 96)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 35, 35, 32)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_194[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 35, 35, 64)   192         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 35, 35, 64)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 35, 35, 96)   55296       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 35, 35, 48)   144         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 35, 35, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 35, 35, 64)   76800       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 35, 35, 96)   82944       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 35, 35, 64)   192         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 35, 35, 96)   288         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 35, 35, 64)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 35, 35, 96)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_201[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 35, 35, 64)   192         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 35, 35, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 35, 35, 96)   55296       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 35, 35, 48)   144         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 35, 35, 48)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 35, 35, 64)   76800       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 35, 35, 96)   82944       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 35, 35, 64)   192         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 35, 35, 96)   288         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 35, 35, 64)   192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 35, 35, 64)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 35, 35, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 35, 35, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_208[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 35, 35, 64)   192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 35, 35, 64)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 35, 35, 96)   55296       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 35, 35, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 35, 35, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 17, 17, 96)   82944       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 17, 17, 384)  1152        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 17, 17, 96)   288         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 17, 17, 384)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 17, 17, 96)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_215[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 17, 17, 128)  114688      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 17, 17, 128)  114688      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 17, 17, 128)  384         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 17, 17, 128)  384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 17, 17, 128)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 17, 17, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 17, 17, 192)  172032      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 17, 17, 192)  172032      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 17, 17, 192)  576         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 17, 17, 192)  576         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 17, 17, 192)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 17, 17, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_219[0][0]             \n",
      "                                                                 activation_222[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "                                                                 activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 17, 17, 160)  179200      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 17, 17, 160)  179200      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 17, 17, 160)  480         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 17, 17, 160)  480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 17, 17, 160)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 17, 17, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 17, 17, 192)  215040      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 17, 17, 192)  215040      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 17, 17, 192)  576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 17, 17, 192)  576         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 17, 17, 192)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 17, 17, 192)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_229[0][0]             \n",
      "                                                                 activation_232[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "                                                                 activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 17, 17, 160)  179200      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 17, 17, 160)  179200      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 17, 17, 160)  480         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 17, 17, 160)  480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 17, 17, 160)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 17, 17, 160)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 17, 17, 192)  215040      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 17, 17, 192)  215040      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 17, 17, 192)  576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 17, 17, 192)  576         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 17, 17, 192)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 17, 17, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_239[0][0]             \n",
      "                                                                 activation_242[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 17, 17, 192)  258048      activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 17, 17, 192)  258048      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_249[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 17, 17, 192)  258048      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 17, 17, 192)  576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 17, 17, 192)  576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 17, 17, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 17, 17, 192)  0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 8, 8, 320)    552960      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 8, 8, 192)    331776      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 8, 8, 320)    960         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 8, 8, 192)    576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 8, 8, 320)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 8, 8, 192)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_260[0][0]             \n",
      "                                                                 activation_264[0][0]             \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 102)          130662      dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,805,510\n",
      "Trainable params: 130,662\n",
      "Non-trainable params: 10,674,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 56s 230ms/step - loss: 2.8606 - acc: 0.4025 - val_loss: 1.7809 - val_acc: 0.6681\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 1.4043 - acc: 0.7438 - val_loss: 1.1039 - val_acc: 0.7976\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.9387 - acc: 0.8403 - val_loss: 0.8003 - val_acc: 0.8602\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.6978 - acc: 0.8820 - val_loss: 0.6539 - val_acc: 0.8793\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.5639 - acc: 0.9037 - val_loss: 0.5644 - val_acc: 0.8970\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.4664 - acc: 0.9206 - val_loss: 0.4928 - val_acc: 0.9110\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 62s 253ms/step - loss: 0.4145 - acc: 0.9263 - val_loss: 0.4482 - val_acc: 0.9051\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 58s 236ms/step - loss: 0.3542 - acc: 0.9352 - val_loss: 0.4163 - val_acc: 0.9154\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.3270 - acc: 0.9384 - val_loss: 0.3927 - val_acc: 0.9132\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.2952 - acc: 0.9459 - val_loss: 0.3725 - val_acc: 0.9146\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.2647 - acc: 0.9510 - val_loss: 0.3429 - val_acc: 0.9169\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.2478 - acc: 0.9516 - val_loss: 0.3292 - val_acc: 0.9191\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2268 - acc: 0.9565 - val_loss: 0.3211 - val_acc: 0.9235\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.2142 - acc: 0.9587 - val_loss: 0.3167 - val_acc: 0.9198\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.2022 - acc: 0.9626 - val_loss: 0.3168 - val_acc: 0.9257\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1807 - acc: 0.9644 - val_loss: 0.2689 - val_acc: 0.9294\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1729 - acc: 0.9684 - val_loss: 0.2892 - val_acc: 0.9249\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.1581 - acc: 0.9695 - val_loss: 0.2680 - val_acc: 0.9308\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 61s 249ms/step - loss: 0.1571 - acc: 0.9709 - val_loss: 0.2528 - val_acc: 0.9375\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.1400 - acc: 0.9741 - val_loss: 0.2738 - val_acc: 0.9264\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.1368 - acc: 0.9719 - val_loss: 0.2487 - val_acc: 0.9345\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1286 - acc: 0.9741 - val_loss: 0.2425 - val_acc: 0.9308\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1244 - acc: 0.9757 - val_loss: 0.2400 - val_acc: 0.9345\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.1248 - acc: 0.9742 - val_loss: 0.2414 - val_acc: 0.9345\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1132 - acc: 0.9763 - val_loss: 0.2271 - val_acc: 0.9426\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.1102 - acc: 0.9805 - val_loss: 0.2238 - val_acc: 0.9382\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.1077 - acc: 0.9789 - val_loss: 0.2328 - val_acc: 0.9330\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1033 - acc: 0.9811 - val_loss: 0.2271 - val_acc: 0.9375\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0992 - acc: 0.9793 - val_loss: 0.2212 - val_acc: 0.9382\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0947 - acc: 0.9808 - val_loss: 0.2168 - val_acc: 0.9397\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0964 - acc: 0.9782 - val_loss: 0.2212 - val_acc: 0.9441\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.0916 - acc: 0.9811 - val_loss: 0.2285 - val_acc: 0.9323\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 60s 245ms/step - loss: 0.0890 - acc: 0.9808 - val_loss: 0.2228 - val_acc: 0.9345\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.0860 - acc: 0.9819 - val_loss: 0.2181 - val_acc: 0.9352\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0853 - acc: 0.9816 - val_loss: 0.2298 - val_acc: 0.9352\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0749 - acc: 0.9850 - val_loss: 0.2280 - val_acc: 0.9294\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0784 - acc: 0.9829 - val_loss: 0.2117 - val_acc: 0.9360\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0775 - acc: 0.9846 - val_loss: 0.2050 - val_acc: 0.9389\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0724 - acc: 0.9845 - val_loss: 0.2255 - val_acc: 0.9272\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0710 - acc: 0.9852 - val_loss: 0.1957 - val_acc: 0.9426\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0692 - acc: 0.9851 - val_loss: 0.2057 - val_acc: 0.9419\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0647 - acc: 0.9868 - val_loss: 0.2006 - val_acc: 0.9433\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0660 - acc: 0.9872 - val_loss: 0.2274 - val_acc: 0.9294\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.0664 - acc: 0.9846 - val_loss: 0.2256 - val_acc: 0.9286\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.0645 - acc: 0.9859 - val_loss: 0.2185 - val_acc: 0.9352\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0610 - acc: 0.9865 - val_loss: 0.2134 - val_acc: 0.9375\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0614 - acc: 0.9864 - val_loss: 0.1950 - val_acc: 0.9426\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0579 - acc: 0.9881 - val_loss: 0.2055 - val_acc: 0.9382\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.0627 - acc: 0.9857 - val_loss: 0.1874 - val_acc: 0.9455\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0634 - acc: 0.9840 - val_loss: 0.2168 - val_acc: 0.9345\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0589 - acc: 0.9862 - val_loss: 0.2180 - val_acc: 0.9330\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0572 - acc: 0.9880 - val_loss: 0.2126 - val_acc: 0.9338\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0530 - acc: 0.9893 - val_loss: 0.2007 - val_acc: 0.9397\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.0538 - acc: 0.9869 - val_loss: 0.2164 - val_acc: 0.9338\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0541 - acc: 0.9869 - val_loss: 0.2017 - val_acc: 0.9367\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0530 - acc: 0.9885 - val_loss: 0.1888 - val_acc: 0.9411\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0537 - acc: 0.9887 - val_loss: 0.1946 - val_acc: 0.9404\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0523 - acc: 0.9866 - val_loss: 0.1886 - val_acc: 0.9441\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0473 - acc: 0.9900 - val_loss: 0.2094 - val_acc: 0.9404\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0521 - acc: 0.9874 - val_loss: 0.1895 - val_acc: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0518 - acc: 0.9883 - val_loss: 0.2134 - val_acc: 0.9397\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0470 - acc: 0.9899 - val_loss: 0.1980 - val_acc: 0.9470\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0473 - acc: 0.9889 - val_loss: 0.2083 - val_acc: 0.9352\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0463 - acc: 0.9885 - val_loss: 0.2084 - val_acc: 0.9360\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.0431 - acc: 0.9885 - val_loss: 0.2101 - val_acc: 0.9367\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0489 - acc: 0.9883 - val_loss: 0.1794 - val_acc: 0.9478\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0482 - acc: 0.9882 - val_loss: 0.2149 - val_acc: 0.9360\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0461 - acc: 0.9895 - val_loss: 0.1865 - val_acc: 0.9455\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.0407 - acc: 0.9905 - val_loss: 0.1956 - val_acc: 0.9360\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0457 - acc: 0.9879 - val_loss: 0.2114 - val_acc: 0.9382\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0422 - acc: 0.9900 - val_loss: 0.1939 - val_acc: 0.9404\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0454 - acc: 0.9880 - val_loss: 0.2155 - val_acc: 0.9367\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.0429 - acc: 0.9900 - val_loss: 0.2029 - val_acc: 0.9397\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0460 - acc: 0.9876 - val_loss: 0.1814 - val_acc: 0.9455\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0398 - acc: 0.9913 - val_loss: 0.2012 - val_acc: 0.9338\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.0413 - acc: 0.9901 - val_loss: 0.1986 - val_acc: 0.9397\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.0400 - acc: 0.9907 - val_loss: 0.1934 - val_acc: 0.9404\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0431 - acc: 0.9885 - val_loss: 0.2050 - val_acc: 0.9404\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0383 - acc: 0.9917 - val_loss: 0.2087 - val_acc: 0.9397\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0435 - acc: 0.9891 - val_loss: 0.1988 - val_acc: 0.9448\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0396 - acc: 0.9896 - val_loss: 0.1877 - val_acc: 0.9455\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0390 - acc: 0.9914 - val_loss: 0.2127 - val_acc: 0.9404\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0376 - acc: 0.9907 - val_loss: 0.1919 - val_acc: 0.9485\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0425 - acc: 0.9892 - val_loss: 0.2137 - val_acc: 0.9352\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0390 - acc: 0.9904 - val_loss: 0.1945 - val_acc: 0.9382\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0403 - acc: 0.9911 - val_loss: 0.1934 - val_acc: 0.9389\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0408 - acc: 0.9899 - val_loss: 0.1834 - val_acc: 0.9433\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0374 - acc: 0.9915 - val_loss: 0.1973 - val_acc: 0.9419\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0380 - acc: 0.9913 - val_loss: 0.1876 - val_acc: 0.9448\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0409 - acc: 0.9901 - val_loss: 0.2019 - val_acc: 0.9404\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.0367 - acc: 0.9900 - val_loss: 0.2021 - val_acc: 0.9382\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0345 - acc: 0.9914 - val_loss: 0.2211 - val_acc: 0.9360\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0348 - acc: 0.9921 - val_loss: 0.1829 - val_acc: 0.9485\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.0348 - acc: 0.9910 - val_loss: 0.2077 - val_acc: 0.9360\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0365 - acc: 0.9891 - val_loss: 0.1929 - val_acc: 0.9463\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0350 - acc: 0.9910 - val_loss: 0.2058 - val_acc: 0.9433\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0381 - acc: 0.9898 - val_loss: 0.1909 - val_acc: 0.9419\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0355 - acc: 0.9899 - val_loss: 0.1877 - val_acc: 0.9389\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0347 - acc: 0.9915 - val_loss: 0.1972 - val_acc: 0.9411\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0353 - acc: 0.9903 - val_loss: 0.2017 - val_acc: 0.9389\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed8')\n",
    "hist8=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep8acc.txt',hist8.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 149, 149, 32) 96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 149, 149, 32) 0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 147, 147, 32) 9216        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 147, 147, 32) 96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 147, 147, 32) 0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 147, 147, 64) 18432       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 147, 147, 64) 192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 147, 147, 64) 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 73, 73, 64)   0           activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 73, 73, 80)   240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 73, 73, 80)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 71, 71, 192)  138240      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 71, 71, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 71, 71, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 35, 35, 192)  0           activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 35, 35, 64)   192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 35, 35, 64)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 35, 35, 96)   55296       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 35, 35, 48)   144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 35, 35, 48)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 35, 35, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 35, 35, 64)   76800       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 35, 35, 96)   82944       activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 35, 35, 64)   192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 35, 35, 96)   288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 35, 35, 32)   96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 35, 35, 64)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 35, 35, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 35, 35, 96)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 35, 35, 32)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_288[0][0]             \n",
      "                                                                 activation_290[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 35, 35, 64)   192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 35, 35, 64)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 35, 35, 96)   55296       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 35, 35, 48)   144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 35, 35, 48)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 35, 35, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 35, 35, 64)   76800       activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 35, 35, 96)   82944       activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 35, 35, 64)   192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 35, 35, 96)   288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 35, 35, 64)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 35, 35, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 35, 35, 96)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 35, 35, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_295[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 35, 35, 64)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 35, 35, 48)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 35, 35, 64)   192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 35, 35, 64)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 35, 35, 96)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 35, 35, 64)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_302[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 35, 35, 64)   192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 35, 35, 64)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 35, 35, 96)   55296       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 35, 35, 96)   288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 35, 35, 96)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 17, 17, 96)   82944       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 17, 17, 384)  1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 17, 17, 96)   288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 17, 17, 384)  0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 17, 17, 96)   0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_309[0][0]             \n",
      "                                                                 activation_312[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 17, 17, 128)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 17, 17, 128)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 17, 17, 128)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 17, 17, 128)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 17, 17, 128)  114688      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 17, 17, 128)  114688      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 17, 17, 128)  384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 17, 17, 128)  0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 17, 17, 128)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 17, 17, 192)  172032      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 17, 17, 192)  172032      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 17, 17, 192)  576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 17, 17, 192)  576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 17, 17, 192)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 17, 17, 192)  0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 17, 17, 192)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_313[0][0]             \n",
      "                                                                 activation_316[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 17, 17, 160)  0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 17, 17, 160)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 17, 17, 160)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 17, 17, 160)  179200      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 17, 17, 160)  179200      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 17, 17, 160)  480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 17, 17, 160)  0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 17, 17, 160)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 17, 17, 192)  215040      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 17, 17, 192)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 17, 17, 192)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 17, 17, 192)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "                                                                 activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 17, 17, 160)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 17, 17, 160)  179200      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 17, 17, 160)  179200      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 17, 17, 160)  480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 17, 17, 160)  480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 17, 17, 160)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 17, 17, 160)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 17, 17, 192)  215040      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 17, 17, 192)  215040      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 17, 17, 192)  576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 17, 17, 192)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 17, 17, 192)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 17, 17, 192)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_333[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 17, 17, 192)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 17, 17, 192)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 17, 17, 192)  258048      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 17, 17, 192)  258048      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 17, 17, 192)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_343[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "                                                                 activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 768)          0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 768)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 102)          78438       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,053,702\n",
      "Trainable params: 78,438\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 59s 242ms/step - loss: 3.8848 - acc: 0.1828 - val_loss: 3.3822 - val_acc: 0.2678\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 3.1367 - acc: 0.3196 - val_loss: 2.8186 - val_acc: 0.3635\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 2.6113 - acc: 0.4462 - val_loss: 2.4020 - val_acc: 0.4378\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 2.2513 - acc: 0.5688 - val_loss: 2.0959 - val_acc: 0.5533\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 1.9622 - acc: 0.6454 - val_loss: 1.8258 - val_acc: 0.6233\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 1.7468 - acc: 0.7066 - val_loss: 1.6469 - val_acc: 0.6954\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 1.5493 - acc: 0.7527 - val_loss: 1.4840 - val_acc: 0.7255\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 1.4097 - acc: 0.7824 - val_loss: 1.3552 - val_acc: 0.7770\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 1.2792 - acc: 0.8077 - val_loss: 1.2372 - val_acc: 0.7962\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 1.1641 - acc: 0.8315 - val_loss: 1.1510 - val_acc: 0.8102\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 1.0839 - acc: 0.8466 - val_loss: 1.0736 - val_acc: 0.8249\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.9980 - acc: 0.8583 - val_loss: 0.9904 - val_acc: 0.8330\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.9333 - acc: 0.8684 - val_loss: 0.9433 - val_acc: 0.8499\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.8747 - acc: 0.8742 - val_loss: 0.8558 - val_acc: 0.8587\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.8230 - acc: 0.8832 - val_loss: 0.8405 - val_acc: 0.8624\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.7660 - acc: 0.8955 - val_loss: 0.7905 - val_acc: 0.8690\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.7371 - acc: 0.8931 - val_loss: 0.7213 - val_acc: 0.8801\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.6937 - acc: 0.8995 - val_loss: 0.7285 - val_acc: 0.8749\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.6702 - acc: 0.9003 - val_loss: 0.6832 - val_acc: 0.8837\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.6197 - acc: 0.9108 - val_loss: 0.6648 - val_acc: 0.8882\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.6045 - acc: 0.9076 - val_loss: 0.6170 - val_acc: 0.9043\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.5714 - acc: 0.9148 - val_loss: 0.5994 - val_acc: 0.8940\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 62s 256ms/step - loss: 0.5480 - acc: 0.9199 - val_loss: 0.5811 - val_acc: 0.9036\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 66s 270ms/step - loss: 0.5350 - acc: 0.9168 - val_loss: 0.5655 - val_acc: 0.9043\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.5088 - acc: 0.9261 - val_loss: 0.5224 - val_acc: 0.9110\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.4902 - acc: 0.9216 - val_loss: 0.5409 - val_acc: 0.9036\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.4664 - acc: 0.9224 - val_loss: 0.5226 - val_acc: 0.9051\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.4550 - acc: 0.9244 - val_loss: 0.4891 - val_acc: 0.9183\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.4483 - acc: 0.9277 - val_loss: 0.4917 - val_acc: 0.9139\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 52s 212ms/step - loss: 0.4238 - acc: 0.9344 - val_loss: 0.4689 - val_acc: 0.9146\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.4128 - acc: 0.9348 - val_loss: 0.4571 - val_acc: 0.9169\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.4024 - acc: 0.9338 - val_loss: 0.4539 - val_acc: 0.9176\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.3950 - acc: 0.9365 - val_loss: 0.4442 - val_acc: 0.9169\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.3825 - acc: 0.9365 - val_loss: 0.4188 - val_acc: 0.9257\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.3632 - acc: 0.9406 - val_loss: 0.4193 - val_acc: 0.9154\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.3625 - acc: 0.9379 - val_loss: 0.4284 - val_acc: 0.9183\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.3632 - acc: 0.9357 - val_loss: 0.3999 - val_acc: 0.9235\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.3396 - acc: 0.9405 - val_loss: 0.3942 - val_acc: 0.9242\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.3375 - acc: 0.9415 - val_loss: 0.3839 - val_acc: 0.9279\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.3284 - acc: 0.9433 - val_loss: 0.3866 - val_acc: 0.9249\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.3222 - acc: 0.9429 - val_loss: 0.3893 - val_acc: 0.9191\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.3119 - acc: 0.9457 - val_loss: 0.3704 - val_acc: 0.9294\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.3107 - acc: 0.9453 - val_loss: 0.3618 - val_acc: 0.9294\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.2999 - acc: 0.9454 - val_loss: 0.3731 - val_acc: 0.9117\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.2907 - acc: 0.9486 - val_loss: 0.3567 - val_acc: 0.9286\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.2973 - acc: 0.9464 - val_loss: 0.3583 - val_acc: 0.9235\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 52s 211ms/step - loss: 0.2780 - acc: 0.9504 - val_loss: 0.3394 - val_acc: 0.9338\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.2713 - acc: 0.9503 - val_loss: 0.3368 - val_acc: 0.9235\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.2756 - acc: 0.9503 - val_loss: 0.3500 - val_acc: 0.9279\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.2682 - acc: 0.9494 - val_loss: 0.3286 - val_acc: 0.9227\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.2622 - acc: 0.9527 - val_loss: 0.3314 - val_acc: 0.9338\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2649 - acc: 0.9518 - val_loss: 0.3387 - val_acc: 0.9279\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.2591 - acc: 0.9509 - val_loss: 0.3216 - val_acc: 0.9286\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.2447 - acc: 0.9561 - val_loss: 0.3207 - val_acc: 0.9323\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2502 - acc: 0.9531 - val_loss: 0.3134 - val_acc: 0.9301\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2381 - acc: 0.9590 - val_loss: 0.3106 - val_acc: 0.9227\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.2452 - acc: 0.9517 - val_loss: 0.3158 - val_acc: 0.9242\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2358 - acc: 0.9536 - val_loss: 0.2934 - val_acc: 0.9397\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2349 - acc: 0.9557 - val_loss: 0.3143 - val_acc: 0.9227\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2273 - acc: 0.9575 - val_loss: 0.2998 - val_acc: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.2243 - acc: 0.9580 - val_loss: 0.3014 - val_acc: 0.9375\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2247 - acc: 0.9577 - val_loss: 0.3046 - val_acc: 0.9272\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2170 - acc: 0.9586 - val_loss: 0.3003 - val_acc: 0.9264\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.2231 - acc: 0.9554 - val_loss: 0.2971 - val_acc: 0.9301\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.2131 - acc: 0.9600 - val_loss: 0.2943 - val_acc: 0.9360\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2111 - acc: 0.9590 - val_loss: 0.2918 - val_acc: 0.9308\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.2072 - acc: 0.9626 - val_loss: 0.2890 - val_acc: 0.9272\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.2003 - acc: 0.9611 - val_loss: 0.2854 - val_acc: 0.9338\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 0.2045 - acc: 0.9580 - val_loss: 0.2713 - val_acc: 0.9360\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2035 - acc: 0.9593 - val_loss: 0.2979 - val_acc: 0.9286\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.2049 - acc: 0.9610 - val_loss: 0.2716 - val_acc: 0.9360\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1949 - acc: 0.9610 - val_loss: 0.2829 - val_acc: 0.9316\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 67s 275ms/step - loss: 0.1966 - acc: 0.9612 - val_loss: 0.2698 - val_acc: 0.9323\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 115s 469ms/step - loss: 0.1979 - acc: 0.9607 - val_loss: 0.2700 - val_acc: 0.9338\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 498s 2s/step - loss: 0.1830 - acc: 0.9641 - val_loss: 0.2852 - val_acc: 0.9294\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 124s 508ms/step - loss: 0.1847 - acc: 0.9636 - val_loss: 0.2731 - val_acc: 0.9301\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1850 - acc: 0.9618 - val_loss: 0.2684 - val_acc: 0.9397\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1817 - acc: 0.9644 - val_loss: 0.2698 - val_acc: 0.9323\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1804 - acc: 0.9657 - val_loss: 0.2667 - val_acc: 0.9301\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1738 - acc: 0.9673 - val_loss: 0.2614 - val_acc: 0.9404\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.1788 - acc: 0.9652 - val_loss: 0.2730 - val_acc: 0.9242\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.1741 - acc: 0.9654 - val_loss: 0.2724 - val_acc: 0.9279\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1771 - acc: 0.9656 - val_loss: 0.2560 - val_acc: 0.9367\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.1708 - acc: 0.9663 - val_loss: 0.2620 - val_acc: 0.9352\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 173s 710ms/step - loss: 0.1741 - acc: 0.9662 - val_loss: 0.2592 - val_acc: 0.9360\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 163s 669ms/step - loss: 0.1653 - acc: 0.9680 - val_loss: 0.2712 - val_acc: 0.9301\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.1668 - acc: 0.9671 - val_loss: 0.2602 - val_acc: 0.9360\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.1635 - acc: 0.9688 - val_loss: 0.2465 - val_acc: 0.9397\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1715 - acc: 0.9644 - val_loss: 0.2537 - val_acc: 0.9367\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1647 - acc: 0.9676 - val_loss: 0.2588 - val_acc: 0.9382\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.1649 - acc: 0.9687 - val_loss: 0.2548 - val_acc: 0.9389\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.1626 - acc: 0.9677 - val_loss: 0.2462 - val_acc: 0.9375\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.1546 - acc: 0.9709 - val_loss: 0.2470 - val_acc: 0.9397\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1592 - acc: 0.9666 - val_loss: 0.2465 - val_acc: 0.9375\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1500 - acc: 0.9689 - val_loss: 0.2405 - val_acc: 0.9389\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1550 - acc: 0.9684 - val_loss: 0.2495 - val_acc: 0.9360\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.1535 - acc: 0.9669 - val_loss: 0.2549 - val_acc: 0.9330\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.1498 - acc: 0.9698 - val_loss: 0.2393 - val_acc: 0.9389\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 58s 240ms/step - loss: 0.1524 - acc: 0.9693 - val_loss: 0.2438 - val_acc: 0.9389\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.1520 - acc: 0.9690 - val_loss: 0.2536 - val_acc: 0.9360\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed7')\n",
    "hist7=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep7acc.txt',hist7.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 768)          0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 102)          78438       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,909,830\n",
      "Trainable params: 78,438\n",
      "Non-trainable params: 6,831,392\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 812s 3s/step - loss: 3.5912 - acc: 0.2313 - val_loss: 2.9193 - val_acc: 0.3466\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 2.6123 - acc: 0.4411 - val_loss: 2.3131 - val_acc: 0.4481\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 2.1066 - acc: 0.5579 - val_loss: 1.9485 - val_acc: 0.5762\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 1.7806 - acc: 0.6367 - val_loss: 1.6849 - val_acc: 0.6130\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 1.5585 - acc: 0.6848 - val_loss: 1.5103 - val_acc: 0.6527\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 1.3810 - acc: 0.7286 - val_loss: 1.3709 - val_acc: 0.6990\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 1.2546 - acc: 0.7545 - val_loss: 1.2720 - val_acc: 0.7079\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 1.1521 - acc: 0.7704 - val_loss: 1.1613 - val_acc: 0.7564\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 1.0767 - acc: 0.7841 - val_loss: 1.1000 - val_acc: 0.7579\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 1.0030 - acc: 0.8040 - val_loss: 1.0645 - val_acc: 0.7564\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.9420 - acc: 0.8055 - val_loss: 0.9838 - val_acc: 0.7800\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.8990 - acc: 0.8136 - val_loss: 0.9480 - val_acc: 0.7822\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.8539 - acc: 0.8230 - val_loss: 0.9082 - val_acc: 0.7947\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 53s 219ms/step - loss: 0.8095 - acc: 0.8334 - val_loss: 0.8865 - val_acc: 0.7903\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.7740 - acc: 0.8349 - val_loss: 0.8279 - val_acc: 0.8146\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.7433 - acc: 0.8368 - val_loss: 0.8187 - val_acc: 0.8168\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.7180 - acc: 0.8446 - val_loss: 0.7905 - val_acc: 0.8182\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.6914 - acc: 0.8533 - val_loss: 0.7763 - val_acc: 0.8175\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.6780 - acc: 0.8457 - val_loss: 0.7486 - val_acc: 0.8227\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.6536 - acc: 0.8549 - val_loss: 0.7315 - val_acc: 0.8278\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.6249 - acc: 0.8616 - val_loss: 0.7177 - val_acc: 0.8300\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.6044 - acc: 0.8670 - val_loss: 0.6984 - val_acc: 0.8359\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.6026 - acc: 0.8642 - val_loss: 0.6839 - val_acc: 0.8403\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.5849 - acc: 0.8671 - val_loss: 0.6784 - val_acc: 0.8396\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.5696 - acc: 0.8665 - val_loss: 0.6498 - val_acc: 0.8425\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.5566 - acc: 0.8745 - val_loss: 0.6340 - val_acc: 0.8469\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.5534 - acc: 0.8749 - val_loss: 0.6398 - val_acc: 0.8447\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.5280 - acc: 0.8754 - val_loss: 0.6281 - val_acc: 0.8418\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.5208 - acc: 0.8816 - val_loss: 0.6103 - val_acc: 0.8499\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.5127 - acc: 0.8797 - val_loss: 0.6055 - val_acc: 0.8499\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 53s 219ms/step - loss: 0.4954 - acc: 0.8846 - val_loss: 0.5893 - val_acc: 0.8521\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.4942 - acc: 0.8816 - val_loss: 0.6032 - val_acc: 0.8477\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.4899 - acc: 0.8820 - val_loss: 0.5764 - val_acc: 0.8536\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.4748 - acc: 0.8898 - val_loss: 0.5743 - val_acc: 0.8521\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.4654 - acc: 0.8863 - val_loss: 0.5556 - val_acc: 0.8595\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.4600 - acc: 0.8899 - val_loss: 0.5815 - val_acc: 0.8528\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.4619 - acc: 0.8863 - val_loss: 0.5727 - val_acc: 0.8514\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.4502 - acc: 0.8872 - val_loss: 0.5458 - val_acc: 0.8587\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.4439 - acc: 0.8922 - val_loss: 0.5417 - val_acc: 0.8595\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.4326 - acc: 0.8929 - val_loss: 0.5403 - val_acc: 0.8661\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.4306 - acc: 0.8926 - val_loss: 0.5281 - val_acc: 0.8580\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.4183 - acc: 0.8975 - val_loss: 0.5407 - val_acc: 0.8653\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.4175 - acc: 0.8977 - val_loss: 0.5197 - val_acc: 0.8624\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.4071 - acc: 0.9024 - val_loss: 0.5182 - val_acc: 0.8609\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.4133 - acc: 0.8979 - val_loss: 0.5038 - val_acc: 0.8749\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 58s 237ms/step - loss: 0.4004 - acc: 0.9017 - val_loss: 0.5213 - val_acc: 0.8587\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.3994 - acc: 0.9036 - val_loss: 0.5033 - val_acc: 0.8683\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.3959 - acc: 0.8991 - val_loss: 0.5146 - val_acc: 0.8639\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.3972 - acc: 0.8983 - val_loss: 0.4843 - val_acc: 0.8756\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.3891 - acc: 0.9034 - val_loss: 0.5104 - val_acc: 0.8720\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 54s 219ms/step - loss: 0.3861 - acc: 0.9011 - val_loss: 0.4994 - val_acc: 0.8683\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.3799 - acc: 0.9040 - val_loss: 0.5029 - val_acc: 0.8683\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.3858 - acc: 0.9020 - val_loss: 0.4778 - val_acc: 0.8749\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.3768 - acc: 0.9012 - val_loss: 0.4790 - val_acc: 0.8786\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.3825 - acc: 0.9020 - val_loss: 0.4825 - val_acc: 0.8756\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.3641 - acc: 0.9071 - val_loss: 0.4772 - val_acc: 0.8771\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3728 - acc: 0.9021 - val_loss: 0.4754 - val_acc: 0.8786\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.3580 - acc: 0.9070 - val_loss: 0.4799 - val_acc: 0.8712\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3534 - acc: 0.9093 - val_loss: 0.4726 - val_acc: 0.8771\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.3648 - acc: 0.9060 - val_loss: 0.4675 - val_acc: 0.8845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.3555 - acc: 0.9089 - val_loss: 0.4711 - val_acc: 0.8771\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3409 - acc: 0.9115 - val_loss: 0.4664 - val_acc: 0.8734\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.3602 - acc: 0.9066 - val_loss: 0.4778 - val_acc: 0.8727\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3423 - acc: 0.9078 - val_loss: 0.4612 - val_acc: 0.8764\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 53s 219ms/step - loss: 0.3488 - acc: 0.9067 - val_loss: 0.4859 - val_acc: 0.8646\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3421 - acc: 0.9082 - val_loss: 0.4449 - val_acc: 0.8815\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.3371 - acc: 0.9121 - val_loss: 0.4452 - val_acc: 0.8764\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.3550 - acc: 0.9036 - val_loss: 0.4414 - val_acc: 0.8867\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.3368 - acc: 0.9114 - val_loss: 0.4449 - val_acc: 0.8808\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 55s 224ms/step - loss: 0.3329 - acc: 0.9101 - val_loss: 0.4434 - val_acc: 0.8830\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 53s 218ms/step - loss: 0.3296 - acc: 0.9060 - val_loss: 0.4464 - val_acc: 0.8756\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3297 - acc: 0.9087 - val_loss: 0.4587 - val_acc: 0.8742\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3278 - acc: 0.9124 - val_loss: 0.4477 - val_acc: 0.8764\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 56s 231ms/step - loss: 0.3323 - acc: 0.9113 - val_loss: 0.4406 - val_acc: 0.8830\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 58s 239ms/step - loss: 0.3267 - acc: 0.9113 - val_loss: 0.4335 - val_acc: 0.8808\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3324 - acc: 0.9092 - val_loss: 0.4250 - val_acc: 0.8867\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.3250 - acc: 0.9119 - val_loss: 0.4161 - val_acc: 0.8867\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3166 - acc: 0.9135 - val_loss: 0.4456 - val_acc: 0.8837\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3130 - acc: 0.9129 - val_loss: 0.4411 - val_acc: 0.8808\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.3153 - acc: 0.9152 - val_loss: 0.4337 - val_acc: 0.8911\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.3091 - acc: 0.9130 - val_loss: 0.4442 - val_acc: 0.8889\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3244 - acc: 0.9084 - val_loss: 0.4276 - val_acc: 0.8874\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3093 - acc: 0.9140 - val_loss: 0.4111 - val_acc: 0.8933\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 57s 232ms/step - loss: 0.3167 - acc: 0.9115 - val_loss: 0.4130 - val_acc: 0.8859\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 55s 227ms/step - loss: 0.3027 - acc: 0.9166 - val_loss: 0.4223 - val_acc: 0.8837\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.3075 - acc: 0.9124 - val_loss: 0.4133 - val_acc: 0.8940\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 56s 227ms/step - loss: 0.3084 - acc: 0.9142 - val_loss: 0.4233 - val_acc: 0.8830\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.2990 - acc: 0.9188 - val_loss: 0.4072 - val_acc: 0.8940\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 56s 230ms/step - loss: 0.3070 - acc: 0.9135 - val_loss: 0.4390 - val_acc: 0.8815\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 56s 229ms/step - loss: 0.3111 - acc: 0.9087 - val_loss: 0.4149 - val_acc: 0.8882\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.3015 - acc: 0.9155 - val_loss: 0.3988 - val_acc: 0.8985\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.2962 - acc: 0.9196 - val_loss: 0.4035 - val_acc: 0.8955\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 56s 227ms/step - loss: 0.3044 - acc: 0.9127 - val_loss: 0.4127 - val_acc: 0.8837\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.2922 - acc: 0.9181 - val_loss: 0.4133 - val_acc: 0.8837\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.2890 - acc: 0.9194 - val_loss: 0.4147 - val_acc: 0.8801\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.2961 - acc: 0.9178 - val_loss: 0.4256 - val_acc: 0.8808\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.2879 - acc: 0.9198 - val_loss: 0.4058 - val_acc: 0.8867\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.2984 - acc: 0.9144 - val_loss: 0.4127 - val_acc: 0.8845\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 55s 226ms/step - loss: 0.2989 - acc: 0.9171 - val_loss: 0.4067 - val_acc: 0.8918\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 54s 222ms/step - loss: 0.2919 - acc: 0.9164 - val_loss: 0.4175 - val_acc: 0.8749\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed6')\n",
    "hist6=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep6acc.txt',hist6.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 768)          0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 102)          78438       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,217,094\n",
      "Trainable params: 78,438\n",
      "Non-trainable params: 5,138,656\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 648s 3s/step - loss: 3.5809 - acc: 0.2469 - val_loss: 2.8915 - val_acc: 0.3547\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 100s 408ms/step - loss: 2.6163 - acc: 0.4320 - val_loss: 2.3311 - val_acc: 0.4555\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 2.1345 - acc: 0.5422 - val_loss: 2.0101 - val_acc: 0.5166\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 1.8447 - acc: 0.6078 - val_loss: 1.7737 - val_acc: 0.5798\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 1.6266 - acc: 0.6576 - val_loss: 1.6171 - val_acc: 0.6152\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 1.4871 - acc: 0.6857 - val_loss: 1.4932 - val_acc: 0.6718\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 47s 193ms/step - loss: 1.3570 - acc: 0.7052 - val_loss: 1.3998 - val_acc: 0.6799\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 1.2603 - acc: 0.7306 - val_loss: 1.3200 - val_acc: 0.6939\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 1.1764 - acc: 0.7474 - val_loss: 1.2570 - val_acc: 0.7101\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 1.1171 - acc: 0.7562 - val_loss: 1.2071 - val_acc: 0.7152\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 1.0643 - acc: 0.7705 - val_loss: 1.1472 - val_acc: 0.7358\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 1.0070 - acc: 0.7798 - val_loss: 1.1262 - val_acc: 0.7277\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.9665 - acc: 0.7889 - val_loss: 1.0974 - val_acc: 0.7425\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.9407 - acc: 0.7892 - val_loss: 1.0458 - val_acc: 0.7542\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.8984 - acc: 0.7931 - val_loss: 1.0195 - val_acc: 0.7623\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.8665 - acc: 0.8050 - val_loss: 0.9914 - val_acc: 0.7616\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 0.8353 - acc: 0.8145 - val_loss: 0.9802 - val_acc: 0.7638\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.8186 - acc: 0.8131 - val_loss: 0.9467 - val_acc: 0.7675\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.7946 - acc: 0.8147 - val_loss: 0.9185 - val_acc: 0.7756\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 48s 196ms/step - loss: 0.7726 - acc: 0.8182 - val_loss: 0.9261 - val_acc: 0.7792\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.7553 - acc: 0.8228 - val_loss: 0.8881 - val_acc: 0.7866\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 0.7466 - acc: 0.8234 - val_loss: 0.8987 - val_acc: 0.7837\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.7290 - acc: 0.8269 - val_loss: 0.8674 - val_acc: 0.7903\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.7011 - acc: 0.8296 - val_loss: 0.8707 - val_acc: 0.7866\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.6866 - acc: 0.8362 - val_loss: 0.8392 - val_acc: 0.7969\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.6706 - acc: 0.8392 - val_loss: 0.8471 - val_acc: 0.7947\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.6648 - acc: 0.8382 - val_loss: 0.8266 - val_acc: 0.7918\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 48s 196ms/step - loss: 0.6378 - acc: 0.8493 - val_loss: 0.8057 - val_acc: 0.8021\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.6419 - acc: 0.8457 - val_loss: 0.8099 - val_acc: 0.8043\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.6311 - acc: 0.8452 - val_loss: 0.8185 - val_acc: 0.7969\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.6280 - acc: 0.8471 - val_loss: 0.7722 - val_acc: 0.8153\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.6158 - acc: 0.8467 - val_loss: 0.7767 - val_acc: 0.8153\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 59s 241ms/step - loss: 0.6072 - acc: 0.8477 - val_loss: 0.7616 - val_acc: 0.8212\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.5934 - acc: 0.8515 - val_loss: 0.7664 - val_acc: 0.8131\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.5945 - acc: 0.8509 - val_loss: 0.7628 - val_acc: 0.8109\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 48s 196ms/step - loss: 0.5678 - acc: 0.8567 - val_loss: 0.7510 - val_acc: 0.8168\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.5694 - acc: 0.8576 - val_loss: 0.7755 - val_acc: 0.8072\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.5709 - acc: 0.8560 - val_loss: 0.7452 - val_acc: 0.8160\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.5511 - acc: 0.8624 - val_loss: 0.7374 - val_acc: 0.8182\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 51s 210ms/step - loss: 0.5493 - acc: 0.8560 - val_loss: 0.7348 - val_acc: 0.8197\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.5443 - acc: 0.8599 - val_loss: 0.7313 - val_acc: 0.8160\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 56s 230ms/step - loss: 0.5359 - acc: 0.8641 - val_loss: 0.7112 - val_acc: 0.8241\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 55s 225ms/step - loss: 0.5313 - acc: 0.8641 - val_loss: 0.7299 - val_acc: 0.8175\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.5255 - acc: 0.8640 - val_loss: 0.7318 - val_acc: 0.8072\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.5223 - acc: 0.8615 - val_loss: 0.7044 - val_acc: 0.8241\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.5194 - acc: 0.8628 - val_loss: 0.7074 - val_acc: 0.8249\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 0.5217 - acc: 0.8633 - val_loss: 0.7088 - val_acc: 0.8197\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.5058 - acc: 0.8639 - val_loss: 0.7130 - val_acc: 0.8190\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.5079 - acc: 0.8653 - val_loss: 0.6935 - val_acc: 0.8234\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.5047 - acc: 0.8680 - val_loss: 0.7003 - val_acc: 0.8212\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4948 - acc: 0.8701 - val_loss: 0.7128 - val_acc: 0.8160\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 56s 229ms/step - loss: 0.4888 - acc: 0.8727 - val_loss: 0.6916 - val_acc: 0.8227\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.4894 - acc: 0.8675 - val_loss: 0.6792 - val_acc: 0.8241\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 0.4824 - acc: 0.8712 - val_loss: 0.6776 - val_acc: 0.8293\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 0.4819 - acc: 0.8699 - val_loss: 0.6660 - val_acc: 0.8308\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.4755 - acc: 0.8745 - val_loss: 0.6804 - val_acc: 0.8315\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.4751 - acc: 0.8697 - val_loss: 0.6823 - val_acc: 0.8234\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.4656 - acc: 0.8797 - val_loss: 0.6580 - val_acc: 0.8286\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.4697 - acc: 0.8768 - val_loss: 0.6704 - val_acc: 0.8286\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4731 - acc: 0.8726 - val_loss: 0.6744 - val_acc: 0.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4583 - acc: 0.8820 - val_loss: 0.6599 - val_acc: 0.8300\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4483 - acc: 0.8811 - val_loss: 0.6698 - val_acc: 0.8256\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.4545 - acc: 0.8773 - val_loss: 0.6767 - val_acc: 0.8234\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4455 - acc: 0.8790 - val_loss: 0.6551 - val_acc: 0.8352\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4449 - acc: 0.8826 - val_loss: 0.6630 - val_acc: 0.8278\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.4441 - acc: 0.8802 - val_loss: 0.6587 - val_acc: 0.8330\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.4493 - acc: 0.8746 - val_loss: 0.6534 - val_acc: 0.8337\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4371 - acc: 0.8776 - val_loss: 0.6454 - val_acc: 0.8300\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4381 - acc: 0.8815 - val_loss: 0.6505 - val_acc: 0.8337\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 48s 199ms/step - loss: 0.4296 - acc: 0.8819 - val_loss: 0.6644 - val_acc: 0.8271\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.4236 - acc: 0.8840 - val_loss: 0.6513 - val_acc: 0.8286\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4356 - acc: 0.8800 - val_loss: 0.6654 - val_acc: 0.8227\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.4241 - acc: 0.8854 - val_loss: 0.6484 - val_acc: 0.8352\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.4295 - acc: 0.8801 - val_loss: 0.6292 - val_acc: 0.8389\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.4343 - acc: 0.8786 - val_loss: 0.6394 - val_acc: 0.8389\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.4281 - acc: 0.8799 - val_loss: 0.6418 - val_acc: 0.8374\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.4246 - acc: 0.8842 - val_loss: 0.6373 - val_acc: 0.8366\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4199 - acc: 0.8845 - val_loss: 0.6616 - val_acc: 0.8256\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.4240 - acc: 0.8842 - val_loss: 0.6515 - val_acc: 0.8308\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4198 - acc: 0.8806 - val_loss: 0.6239 - val_acc: 0.8381\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.4121 - acc: 0.8854 - val_loss: 0.6317 - val_acc: 0.8337\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4254 - acc: 0.8780 - val_loss: 0.6345 - val_acc: 0.8300\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4190 - acc: 0.8813 - val_loss: 0.6376 - val_acc: 0.8271\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.4079 - acc: 0.8877 - val_loss: 0.6765 - val_acc: 0.8138\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.4140 - acc: 0.8835 - val_loss: 0.6241 - val_acc: 0.8374\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.3898 - acc: 0.8939 - val_loss: 0.6642 - val_acc: 0.8219\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.4132 - acc: 0.8859 - val_loss: 0.6318 - val_acc: 0.8278\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.4001 - acc: 0.8890 - val_loss: 0.6434 - val_acc: 0.8308\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.3956 - acc: 0.8898 - val_loss: 0.6314 - val_acc: 0.8330\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.3960 - acc: 0.8890 - val_loss: 0.6136 - val_acc: 0.8359\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 56s 231ms/step - loss: 0.4002 - acc: 0.8834 - val_loss: 0.6237 - val_acc: 0.8389\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 50s 203ms/step - loss: 0.4014 - acc: 0.8862 - val_loss: 0.6311 - val_acc: 0.8300\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.3877 - acc: 0.8888 - val_loss: 0.6383 - val_acc: 0.8227\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.3954 - acc: 0.8879 - val_loss: 0.6309 - val_acc: 0.8300\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.3878 - acc: 0.8923 - val_loss: 0.6290 - val_acc: 0.8278\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.3999 - acc: 0.8869 - val_loss: 0.6245 - val_acc: 0.8315\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 0.3896 - acc: 0.8870 - val_loss: 0.6319 - val_acc: 0.8308\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.3900 - acc: 0.8886 - val_loss: 0.6258 - val_acc: 0.8366\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 0.3883 - acc: 0.8876 - val_loss: 0.6118 - val_acc: 0.8330\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.3934 - acc: 0.8900 - val_loss: 0.6238 - val_acc: 0.8381\n"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed5')\n",
    "hist5=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep5acc.txt',hist5.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 149, 149, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 149, 149, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 147, 147, 32) 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 147, 147, 32) 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 147, 147, 32) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 147, 147, 64) 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 147, 147, 64) 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 147, 147, 64) 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 73, 73, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 73, 73, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 71, 71, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 71, 71, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 71, 71, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 35, 35, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 35, 35, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 35, 35, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 35, 35, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 35, 35, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 35, 35, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 35, 35, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 35, 35, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 35, 35, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 35, 35, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 35, 35, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 35, 35, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 35, 35, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 35, 35, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 35, 35, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 35, 35, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 35, 35, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 35, 35, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 35, 35, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 35, 35, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 35, 35, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 35, 35, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 35, 35, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 35, 35, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 35, 35, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 35, 35, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 35, 35, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 35, 35, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 35, 35, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 35, 35, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 35, 35, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 35, 35, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 35, 35, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 35, 35, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 35, 35, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 35, 35, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 35, 35, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 35, 35, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 35, 35, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 35, 35, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 35, 35, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 35, 35, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 96)   82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 384)  1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 96)   288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 384)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 96)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 128)  114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 128)  114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 128)  384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 128)  384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 192)  172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 768)          0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 102)          78438       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,524,358\n",
      "Trainable params: 78,438\n",
      "Non-trainable params: 3,445,920\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/244 [==========>...................] - ETA: 39s - loss: 4.0904 - acc: 0.1480"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed4')\n",
    "hist4=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep4acc.txt',hist4.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=base_model('mixed3')\n",
    "hist3=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep3acc.txt',hist3.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=base_model('mixed2')\n",
    "hist2=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep2acc.txt',hist2.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=base_model('mixed1')\n",
    "hist1=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep1acc.txt',hist1.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 256)          0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 102)          26214       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 455,654\n",
      "Trainable params: 26,214\n",
      "Non-trainable params: 429,440\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 768s 3s/step - loss: 4.6832 - acc: 0.0792 - val_loss: 3.7930 - val_acc: 0.2156\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 4.1260 - acc: 0.1650 - val_loss: 3.5411 - val_acc: 0.2929\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 3.8117 - acc: 0.2300 - val_loss: 3.4006 - val_acc: 0.2539\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 3.5905 - acc: 0.2600 - val_loss: 3.2776 - val_acc: 0.2870\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 3.4493 - acc: 0.2898 - val_loss: 3.2167 - val_acc: 0.2958\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 61s 250ms/step - loss: 3.3321 - acc: 0.3023 - val_loss: 3.1031 - val_acc: 0.3223\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 57s 232ms/step - loss: 3.2465 - acc: 0.3083 - val_loss: 2.9959 - val_acc: 0.3407\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 53s 219ms/step - loss: 3.1712 - acc: 0.3226 - val_loss: 2.9920 - val_acc: 0.3319\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 51s 208ms/step - loss: 3.0981 - acc: 0.3282 - val_loss: 3.0071 - val_acc: 0.3208\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 53s 215ms/step - loss: 3.0627 - acc: 0.3387 - val_loss: 2.9375 - val_acc: 0.3341\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 53s 216ms/step - loss: 3.0021 - acc: 0.3467 - val_loss: 2.8952 - val_acc: 0.3444\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 2.9655 - acc: 0.3461 - val_loss: 2.8018 - val_acc: 0.3628\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 2.9220 - acc: 0.3601 - val_loss: 2.8614 - val_acc: 0.3503\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 2.9022 - acc: 0.3596 - val_loss: 2.8830 - val_acc: 0.3326\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 2.8745 - acc: 0.3663 - val_loss: 2.7462 - val_acc: 0.3782\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 52s 213ms/step - loss: 2.8484 - acc: 0.3663 - val_loss: 2.7455 - val_acc: 0.3745\n",
      "Epoch 17/100\n",
      "223/244 [==========================>...] - ETA: 3s - loss: 2.8214 - acc: 0.3673"
     ]
    }
   ],
   "source": [
    "model=base_model('mixed0')\n",
    "hist0=model.fit_generator(train_generator,\n",
    "                    epochs = 100,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Incep0acc.txt',hist0.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Feature Extraction using numpy pooling\n",
    "############################################\n",
    "#which base model to extract features\n",
    "#which layer(name) to extract features\n",
    "#X: input data(a generator)\n",
    "#steps: steps for predict_generator \n",
    "#size: block_size for image downsampling\n",
    "def extract_features(base, name, X,step,size):\n",
    "    target = Model(inputs=base.input,outputs=base.get_layer(name).output)\n",
    "    features = target.predict_generator(X,steps=steps,verbose=1)\n",
    "    n,a,b,c=features.shape\n",
    "    features1=[]\n",
    "    for i in range(n):\n",
    "        new=block_reduce(features[i,:,:,:], block_size=(size,size,1), func=np.mean)\n",
    "        a,b,c=new.shape\n",
    "        features1.append(new.reshape(a*b*c))\n",
    "    features1=np.stack(features1)\n",
    "    return features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1359 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "#    '/pylon5/ms3uujp/dx10384/caltech101/101_ObjectCategories',\n",
    "    target_size = (299, 299),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= val_generator.classes\n",
    "steps=len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = InceptionV3(weights='imagenet', include_top=False, input_shape = (299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359/1359 [==============================] - 69s 51ms/step\n",
      "1359/1359 [==============================] - 13s 10ms/step\n",
      "1359/1359 [==============================] - 14s 10ms/step\n",
      "1359/1359 [==============================] - 14s 10ms/step\n",
      "1359/1359 [==============================] - 15s 11ms/step\n",
      "1359/1359 [==============================] - 16s 12ms/step\n",
      "1359/1359 [==============================] - 18s 13ms/step\n",
      "1359/1359 [==============================] - 20s 15ms/step\n",
      "1359/1359 [==============================] - 21s 15ms/step\n",
      "1359/1359 [==============================] - 24s 18ms/step\n",
      "1359/1359 [==============================] - 28s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "feature1=extract_features(base,'mixed0',val_generator,steps,35)\n",
    "feature2=extract_features(base,'mixed1',val_generator,steps,35)\n",
    "feature3=extract_features(base,'mixed2',val_generator,steps,35)\n",
    "feature4=extract_features(base,'mixed3',val_generator,steps,17)\n",
    "feature5=extract_features(base,'mixed4',val_generator,steps,17)\n",
    "feature6=extract_features(base,'mixed5',val_generator,steps,17)\n",
    "feature7=extract_features(base,'mixed6',val_generator,steps,17)\n",
    "feature8=extract_features(base,'mixed7',val_generator,steps,17)\n",
    "feature9=extract_features(base,'mixed8',val_generator,steps,8)\n",
    "feature10=extract_features(base,'mixed9',val_generator,steps,8)\n",
    "feature11=extract_features(base,'mixed10',val_generator,steps,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Projection correlation & Distance correlation\n",
    "##################################################\n",
    "\n",
    "def get_arccos_1d(X):\n",
    "\n",
    "    # X -- a 1D array\n",
    "    \n",
    "    X = np.squeeze(X)\n",
    "    Y = X[:,None] - X\n",
    "    Z = Y.T[:,:,None]*Y.T[:,None]\n",
    "    n = len(X)\n",
    "    \n",
    "    a = np.zeros([n, n, n])\n",
    "    a[Z == 0.] = np.pi/2.\n",
    "    a[Z < 0.] = np.pi\n",
    "    \n",
    "    a = np.transpose(a, (1,2,0))\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "    \n",
    "    return a, A\n",
    "\n",
    "\n",
    "def get_arccos(X):\n",
    "\n",
    "    # X -- a 2D array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    cos_a = np.zeros([n, n, n])\n",
    "    \n",
    "    for r in range(n):\n",
    "        \n",
    "        xr = X[r]\n",
    "        X_r = X - xr\n",
    "        cross = np.dot(X_r, X_r.T)\n",
    "        row_norm = np.sqrt(np.sum(X_r**2, axis = 1))\n",
    "        outer_norm = np.outer(row_norm, row_norm)\n",
    "        \n",
    "        zero_idx = (outer_norm == 0.)\n",
    "        outer_norm[zero_idx] = 1.\n",
    "        cos_a_kl = cross / outer_norm\n",
    "        cos_a_kl[zero_idx] = 0.\n",
    "\n",
    "        cos_a[:,:,r] = cos_a_kl\n",
    "        \n",
    "    cos_a[cos_a > 1] = 1.\n",
    "    cos_a[cos_a < -1] = -1.\n",
    "    a = np.arccos(cos_a)\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "        \n",
    "    return a, A\n",
    "\n",
    "def projection_corr_1dy(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the projection correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*1 2D array\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def distance_corr(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the distance correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*p 2D array\n",
    "\n",
    "    return: a list of two elements: \n",
    "            [distance correlation, bias-corrected distance correlation]\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    if n < 4:\n",
    "        raise ValueError(\"sample size is less than 4.\")\n",
    "        \n",
    "    outer_diff_x = X[:, np.newaxis] - X\n",
    "    outer_diff_y = Y[:, np.newaxis] - Y\n",
    "    \n",
    "    a = np.linalg.norm(outer_diff_x, axis = 2)\n",
    "    b = np.linalg.norm(outer_diff_y, axis = 2)\n",
    "    \n",
    "    a0_bar = np.mean(a, axis = 0, keepdims = True)\n",
    "    a1_bar = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    b0_bar = np.mean(b, axis = 0, keepdims = True)\n",
    "    b1_bar = np.mean(b, axis = 1, keepdims = True)\n",
    "    b_bar  = np.mean(b, axis = (0,1), keepdims = True)\n",
    "    \n",
    "    A = a - a0_bar - a1_bar + a_bar\n",
    "    B = b - b0_bar - b1_bar + b_bar\n",
    "    \n",
    "    S_xy = np.sum(A*B)\n",
    "    S_xx = np.sum(A**2)\n",
    "    S_yy = np.sum(B**2)\n",
    "    \n",
    "    if S_xy * S_xx == 0.:\n",
    "        corr1 = 0.\n",
    "    else:\n",
    "        corr1 = np.sqrt(S_xy / np.sqrt(S_xx * S_yy))\n",
    "        \n",
    "    A_tilde = a - n*a0_bar/(n-2.) - n*a1_bar/(n-2.) + n*n*a_bar/((n-1.)*(n-2.))\n",
    "    B_tilde = b - n*b0_bar/(n-2.) - n*b1_bar/(n-2.) + n*n*b_bar/((n-1.)*(n-2.))\n",
    "    np.fill_diagonal(A_tilde, 0.)\n",
    "    np.fill_diagonal(B_tilde, 0.)\n",
    "    \n",
    "    S_xy_tilde = np.sum(A_tilde*B_tilde)\n",
    "    S_xx_tilde = np.sum(A_tilde**2)\n",
    "    S_yy_tilde = np.sum(B_tilde**2)\n",
    "    \n",
    "    if S_xy_tilde * S_xx_tilde == 0.:\n",
    "        corr3 = 0.\n",
    "    else:\n",
    "        corr3 = S_xy_tilde / np.sqrt(S_xx_tilde * S_yy_tilde)\n",
    "    \n",
    "    return [corr1, corr3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "from sklearn.utils import shuffle\n",
    "nsample=np.array([500,1000,1500])\n",
    "subfeature1,sublabel1=shuffle(feature1,label,n_samples=nsample[j])\n",
    "subfeature2,sublabel2=shuffle(feature2,label,n_samples=nsample[j])\n",
    "subfeature3,sublabel3=shuffle(feature3,label,n_samples=nsample[j])\n",
    "subfeature4,sublabel4=shuffle(feature4,label,n_samples=nsample[j])\n",
    "subfeature5,sublabel5=shuffle(feature5,label,n_samples=nsample[j])\n",
    "subfeature6,sublabel6=shuffle(feature6,label,n_samples=nsample[j])\n",
    "subfeature7,sublabel7=shuffle(feature7,label,n_samples=nsample[j])\n",
    "subfeature8,sublabel8=shuffle(feature8,label,n_samples=nsample[j])\n",
    "subfeature9,sublabel9=shuffle(feature9,label,n_samples=nsample[j])\n",
    "subfeature10,sublabel10=shuffle(feature10,label,n_samples=nsample[j])\n",
    "subfeature11,sublabel11=shuffle(feature11,label,n_samples=nsample[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18678991155780364\n",
      "0.19121241992449575\n",
      "0.23617342279109474\n",
      "0.2580383245790337\n",
      "0.3244303306536486\n",
      "0.33725607228313753\n",
      "0.37315819275569667\n",
      "0.3251593439002487\n"
     ]
    }
   ],
   "source": [
    "print (projection_corr_1dy(subfeature1,sublabel1.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature2,sublabel2.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature3,sublabel3.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature4,sublabel4.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature5,sublabel5.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature6,sublabel6.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature7,sublabel7.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature8,sublabel8.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature9,sublabel9.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature10,sublabel10.reshape(-1,1)))\n",
    "print (projection_corr_1dy(subfeature11,sublabel11.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
