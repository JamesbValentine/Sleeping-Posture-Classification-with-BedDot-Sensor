{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from skimage.measure import block_reduce \n",
    "from keras.models import load_model,Model,Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Activation\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "    \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator for training set\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "# data generator for test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7785 images belonging to 102 classes.\n",
      "Found 1359 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "steps_per_epoch=np.ceil(7785/batch_size)\n",
    "validation_steps=np.ceil(1359/batch_size)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/101_ObjectCategories',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####create model\n",
    "def base_model(name):\n",
    "    base_model = VGG16(weights = \"imagenet\", include_top=False, input_shape = (224,224,3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.get_layer(name).output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(102, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 45,820,070\n",
      "Trainable params: 25,795,686\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 41s 168ms/step - loss: 11.9542 - acc: 0.2400 - val_loss: 9.9613 - val_acc: 0.3557\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 8.9212 - acc: 0.4259 - val_loss: 8.2012 - val_acc: 0.4755\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 39s 158ms/step - loss: 8.0918 - acc: 0.4838 - val_loss: 7.7769 - val_acc: 0.5041\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 43s 178ms/step - loss: 7.2229 - acc: 0.5371 - val_loss: 7.0187 - val_acc: 0.5516\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 40s 165ms/step - loss: 6.6649 - acc: 0.5752 - val_loss: 6.6786 - val_acc: 0.5757\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 5.1374 - acc: 0.6682 - val_loss: 4.7059 - val_acc: 0.6910\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 4.4245 - acc: 0.7151 - val_loss: 4.2630 - val_acc: 0.7182\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 4.2896 - acc: 0.7246 - val_loss: 4.4801 - val_acc: 0.7061\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 4.1156 - acc: 0.7365 - val_loss: 4.4297 - val_acc: 0.7129\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 3.9310 - acc: 0.7497 - val_loss: 3.9949 - val_acc: 0.7393\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 3.7004 - acc: 0.7625 - val_loss: 3.7541 - val_acc: 0.7551\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 39s 162ms/step - loss: 3.4030 - acc: 0.7796 - val_loss: 3.1771 - val_acc: 0.7890\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 3.0500 - acc: 0.8014 - val_loss: 2.9433 - val_acc: 0.8018\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 2.8271 - acc: 0.8158 - val_loss: 2.7801 - val_acc: 0.8146\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 40s 163ms/step - loss: 2.6239 - acc: 0.8301 - val_loss: 2.7101 - val_acc: 0.8184\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 40s 165ms/step - loss: 2.5522 - acc: 0.8349 - val_loss: 2.5910 - val_acc: 0.8229\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 56s 232ms/step - loss: 2.4689 - acc: 0.8410 - val_loss: 2.6212 - val_acc: 0.8191\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 40s 163ms/step - loss: 2.4159 - acc: 0.8456 - val_loss: 2.5260 - val_acc: 0.8312\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 45s 184ms/step - loss: 2.3468 - acc: 0.8508 - val_loss: 2.6155 - val_acc: 0.8244\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 40s 166ms/step - loss: 2.3972 - acc: 0.8481 - val_loss: 2.4426 - val_acc: 0.8312\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 39s 163ms/step - loss: 2.1734 - acc: 0.8609 - val_loss: 2.5140 - val_acc: 0.8304\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 1.9832 - acc: 0.8700 - val_loss: 2.2651 - val_acc: 0.8455\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 40s 166ms/step - loss: 1.9617 - acc: 0.8734 - val_loss: 2.3830 - val_acc: 0.8357\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 1.8467 - acc: 0.8818 - val_loss: 2.2542 - val_acc: 0.8515\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 1.7122 - acc: 0.8883 - val_loss: 1.9371 - val_acc: 0.8696\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 1.6718 - acc: 0.8934 - val_loss: 2.0495 - val_acc: 0.8606\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 38s 156ms/step - loss: 1.6098 - acc: 0.8970 - val_loss: 2.1305 - val_acc: 0.8561\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 1.6046 - acc: 0.8977 - val_loss: 1.9604 - val_acc: 0.8711\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 1.5481 - acc: 0.9019 - val_loss: 1.8653 - val_acc: 0.8681\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 1.4806 - acc: 0.9066 - val_loss: 2.1043 - val_acc: 0.8591\n"
     ]
    }
   ],
   "source": [
    "model=base_model('block5_pool')\n",
    "hist10=model.fit_generator(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               51380736  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               52326     \n",
      "=================================================================\n",
      "Total params: 59,068,326\n",
      "Trainable params: 51,433,062\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 381s 2s/step - loss: 15.2917 - acc: 0.0512 - val_loss: 15.3146 - val_acc: 0.0499\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 72s 296ms/step - loss: 15.2910 - acc: 0.0513 - val_loss: 15.3164 - val_acc: 0.0497\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 61s 250ms/step - loss: 15.2858 - acc: 0.0516 - val_loss: 15.3164 - val_acc: 0.0497\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 48s 198ms/step - loss: 15.2973 - acc: 0.0509 - val_loss: 15.3043 - val_acc: 0.0505\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 42s 173ms/step - loss: 15.2869 - acc: 0.0516 - val_loss: 15.4379 - val_acc: 0.0422\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2993 - acc: 0.0508 - val_loss: 15.3164 - val_acc: 0.0497\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2899 - acc: 0.0514 - val_loss: 15.2679 - val_acc: 0.0528\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2775 - acc: 0.0522 - val_loss: 15.2800 - val_acc: 0.0520\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 15.2973 - acc: 0.0509 - val_loss: 15.3286 - val_acc: 0.0490\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2993 - acc: 0.0508 - val_loss: 15.4258 - val_acc: 0.0430\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2827 - acc: 0.0518 - val_loss: 15.1828 - val_acc: 0.0580\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 39s 159ms/step - loss: 15.3014 - acc: 0.0507 - val_loss: 15.3772 - val_acc: 0.0460\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 15.2775 - acc: 0.0522 - val_loss: 15.3893 - val_acc: 0.0452\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2993 - acc: 0.0508 - val_loss: 15.3043 - val_acc: 0.0505\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 38s 158ms/step - loss: 15.2869 - acc: 0.0516 - val_loss: 15.3286 - val_acc: 0.0490\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 38s 155ms/step - loss: 15.2993 - acc: 0.0508 - val_loss: 15.3043 - val_acc: 0.0505\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 38s 156ms/step - loss: 15.3014 - acc: 0.0507 - val_loss: 15.3043 - val_acc: 0.0505\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 15.2630 - acc: 0.0531 - val_loss: 15.3407 - val_acc: 0.0482\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 38s 155ms/step - loss: 15.2993 - acc: 0.0508 - val_loss: 15.3043 - val_acc: 0.0505\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 38s 154ms/step - loss: 15.2931 - acc: 0.0512 - val_loss: 15.3772 - val_acc: 0.0460\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 15.2848 - acc: 0.0517 - val_loss: 15.3529 - val_acc: 0.0475\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 37s 154ms/step - loss: 15.3118 - acc: 0.0500 - val_loss: 15.2921 - val_acc: 0.0512\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 38s 156ms/step - loss: 15.2941 - acc: 0.0511 - val_loss: 15.2800 - val_acc: 0.0520\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 37s 154ms/step - loss: 15.2567 - acc: 0.0534 - val_loss: 15.2921 - val_acc: 0.0512\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 39s 161ms/step - loss: 15.2961 - acc: 0.0510 - val_loss: 15.3529 - val_acc: 0.0475\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 38s 156ms/step - loss: 15.2837 - acc: 0.0518 - val_loss: 15.2921 - val_acc: 0.0512\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 38s 157ms/step - loss: 15.3055 - acc: 0.0504 - val_loss: 15.3650 - val_acc: 0.0467\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 39s 160ms/step - loss: 15.2682 - acc: 0.0527 - val_loss: 15.2921 - val_acc: 0.0512\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 38s 155ms/step - loss: 15.3055 - acc: 0.0504 - val_loss: 15.4015 - val_acc: 0.0445\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 38s 156ms/step - loss: 15.2786 - acc: 0.0521 - val_loss: 15.2800 - val_acc: 0.0520\n"
     ]
    }
   ],
   "source": [
    "model=base_model('block4_pool')\n",
    "hist4=model.fit_generator(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=243,\n",
    "                    validation_steps=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=base_model('block3_pool')\n",
    "hist4=model.fit_generator(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=243,\n",
    "                    validation_steps=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              411042816 \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 411,407,526\n",
      "Trainable params: 411,147,366\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[401408,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_6/RMSprop/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7f6388ce6ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m243\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_steps=42)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[401408,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_6/RMSprop/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model=base_model('block2_pool')\n",
    "hist4=model.fit_generator(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=243,\n",
    "                    validation_steps=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=base_model('block1_pool')\n",
    "hist4=model.fit_generator(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=243,\n",
    "                    validation_steps=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               3342438   \n",
      "=================================================================\n",
      "Total params: 18,057,126\n",
      "Trainable params: 3,342,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "####          Model Preparation \n",
    "############################################\n",
    "\n",
    "base_model = VGG16(weights = \"imagenet\", include_top=False, input_shape = (256,256,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "#x = Dense(1024, activation=\"relu\")(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(102, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7785 images belonging to 102 classes.\n",
      "Found 1359 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# data generator for training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "\n",
    "# data generator for test set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/101_ObjectCategories',\n",
    "    target_size = (256, 256),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (256, 256),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    epochs = 50,\n",
    "                    validation_data = test_generator,\n",
    "                    steps_per_epoch=243,\n",
    "                    validation_steps=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Feature Extraction using numpy pooling\n",
    "############################################\n",
    "#which base model to extract features\n",
    "#which layer(name) to extract features\n",
    "#X: input data(a generator)\n",
    "#steps: steps for predict_generator \n",
    "#size: block_size for image downsampling\n",
    "def extract_features(base, name, X,step,size):\n",
    "    target = Model(inputs=base.input,outputs=base.get_layer(name).output)\n",
    "    features = target.predict_generator(test_generator,steps=steps,verbose=1)\n",
    "    n,a,b,c=features.shape\n",
    "    features1=[]\n",
    "    for i in range(n):\n",
    "        new=block_reduce(features[i,:,:,:], block_size=(size,size,1), func=np.mean)\n",
    "        a,b,c=new.shape\n",
    "        features1.append(new.reshape(a*b*c))\n",
    "    features1=np.stack(features1)\n",
    "    return features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1359 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (256, 256),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= test_generator.classes\n",
    "steps=len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359/1359 [==============================] - 19s 14ms/step\n",
      "1359/1359 [==============================] - 11s 8ms/step\n",
      "1359/1359 [==============================] - 11s 8ms/step\n",
      "1359/1359 [==============================] - 12s 9ms/step\n",
      "1359/1359 [==============================] - 13s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "feature1=extract_features(base,'block1_pool',test_generator,steps,16)\n",
    "feature2=extract_features(base,'block2_pool',test_generator,steps,16)\n",
    "feature3=extract_features(base,'block3_pool',test_generator,steps,8)\n",
    "feature4=extract_features(base,'block4_pool',test_generator,steps,8)\n",
    "feature5=extract_features(base,'block5_pool',test_generator,steps,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Projection correlation & Distance correlation\n",
    "##################################################\n",
    "\n",
    "def get_arccos_1d(X):\n",
    "\n",
    "    # X -- a 1D array\n",
    "    \n",
    "    X = np.squeeze(X)\n",
    "    Y = X[:,None] - X\n",
    "    Z = Y.T[:,:,None]*Y.T[:,None]\n",
    "    n = len(X)\n",
    "    \n",
    "    a = np.zeros([n, n, n])\n",
    "    a[Z == 0.] = np.pi/2.\n",
    "    a[Z < 0.] = np.pi\n",
    "    \n",
    "    a = np.transpose(a, (1,2,0))\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "    \n",
    "    return a, A\n",
    "\n",
    "\n",
    "def get_arccos(X):\n",
    "\n",
    "    # X -- a 2D array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    cos_a = np.zeros([n, n, n])\n",
    "    \n",
    "    for r in range(n):\n",
    "        \n",
    "        xr = X[r]\n",
    "        X_r = X - xr\n",
    "        cross = np.dot(X_r, X_r.T)\n",
    "        row_norm = np.sqrt(np.sum(X_r**2, axis = 1))\n",
    "        outer_norm = np.outer(row_norm, row_norm)\n",
    "        \n",
    "        zero_idx = (outer_norm == 0.)\n",
    "        outer_norm[zero_idx] = 1.\n",
    "        cos_a_kl = cross / outer_norm\n",
    "        cos_a_kl[zero_idx] = 0.\n",
    "\n",
    "        cos_a[:,:,r] = cos_a_kl\n",
    "        \n",
    "    cos_a[cos_a > 1] = 1.\n",
    "    cos_a[cos_a < -1] = -1.\n",
    "    a = np.arccos(cos_a)\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "        \n",
    "    return a, A\n",
    "\n",
    "def projection_corr_1dy(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the projection correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*1 2D array\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def distance_corr(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the distance correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*p 2D array\n",
    "\n",
    "    return: a list of two elements: \n",
    "            [distance correlation, bias-corrected distance correlation]\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    if n < 4:\n",
    "        raise ValueError(\"sample size is less than 4.\")\n",
    "        \n",
    "    outer_diff_x = X[:, np.newaxis] - X\n",
    "    outer_diff_y = Y[:, np.newaxis] - Y\n",
    "    \n",
    "    a = np.linalg.norm(outer_diff_x, axis = 2)\n",
    "    b = np.linalg.norm(outer_diff_y, axis = 2)\n",
    "    \n",
    "    a0_bar = np.mean(a, axis = 0, keepdims = True)\n",
    "    a1_bar = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    b0_bar = np.mean(b, axis = 0, keepdims = True)\n",
    "    b1_bar = np.mean(b, axis = 1, keepdims = True)\n",
    "    b_bar  = np.mean(b, axis = (0,1), keepdims = True)\n",
    "    \n",
    "    A = a - a0_bar - a1_bar + a_bar\n",
    "    B = b - b0_bar - b1_bar + b_bar\n",
    "    \n",
    "    S_xy = np.sum(A*B)\n",
    "    S_xx = np.sum(A**2)\n",
    "    S_yy = np.sum(B**2)\n",
    "    \n",
    "    if S_xy * S_xx == 0.:\n",
    "        corr1 = 0.\n",
    "    else:\n",
    "        corr1 = np.sqrt(S_xy / np.sqrt(S_xx * S_yy))\n",
    "        \n",
    "    A_tilde = a - n*a0_bar/(n-2.) - n*a1_bar/(n-2.) + n*n*a_bar/((n-1.)*(n-2.))\n",
    "    B_tilde = b - n*b0_bar/(n-2.) - n*b1_bar/(n-2.) + n*n*b_bar/((n-1.)*(n-2.))\n",
    "    np.fill_diagonal(A_tilde, 0.)\n",
    "    np.fill_diagonal(B_tilde, 0.)\n",
    "    \n",
    "    S_xy_tilde = np.sum(A_tilde*B_tilde)\n",
    "    S_xx_tilde = np.sum(A_tilde**2)\n",
    "    S_yy_tilde = np.sum(B_tilde**2)\n",
    "    \n",
    "    if S_xy_tilde * S_xx_tilde == 0.:\n",
    "        corr3 = 0.\n",
    "    else:\n",
    "        corr3 = S_xy_tilde / np.sqrt(S_xx_tilde * S_yy_tilde)\n",
    "    \n",
    "    return [corr1, corr3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis1=distance_corr(feature1,label.reshape(-1,1))\n",
    "dis2=distance_corr(feature2,label.reshape(-1,1))\n",
    "dis3=distance_corr(feature3,label.reshape(-1,1))\n",
    "dis4=distance_corr(feature4,label.reshape(-1,1))\n",
    "dis5=distance_corr(feature5,label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19956280117031025, 0.033402860705677336]\n",
      "[0.23150005391473327, 0.04715629750509841]\n",
      "[0.3086559500180125, 0.08842580010870653]\n",
      "[0.347464970483844, 0.1144196109145059]\n",
      "[0.38064744428025504, 0.13983810424604773]\n"
     ]
    }
   ],
   "source": [
    "print (dis1)\n",
    "print (dis2)\n",
    "print (dis3)\n",
    "print (dis4)\n",
    "print (dis5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
