{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from skimage.measure import block_reduce \n",
    "from keras.models import load_model,Model,Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Activation\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "    \n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator for training set\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "# data generator for test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/101_ObjectCategories',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dx10384/.conda/envs/keras_env/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base = ResNet50(weights='imagenet', include_top=False, input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Feature Extraction using numpy pooling\n",
    "############################################\n",
    "#which base model to extract features\n",
    "#which layer(name) to extract features\n",
    "#X: input data(a generator)\n",
    "#steps: steps for predict_generator \n",
    "#size: block_size for image downsampling\n",
    "def extract_features(base, name, X,step,size):\n",
    "    target = Model(inputs=base.input,outputs=base.get_layer(name).output)\n",
    "    features = target.predict_generator(X,steps=steps,verbose=1)\n",
    "    n,a,b,c=features.shape\n",
    "    features1=[]\n",
    "    for i in range(n):\n",
    "        new=block_reduce(features[i,:,:,:], block_size=(size,size,1), func=np.mean)\n",
    "        a,b,c=new.shape\n",
    "        features1.append(new.reshape(a*b*c))\n",
    "    features1=np.stack(features1)\n",
    "    return features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = test_datagen.flow_from_directory(\n",
    "    '/pylon5/ms3uujp/dx10384/caltech101/test',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 1,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= val_generator.classes\n",
    "steps=len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "feature1=extract_features(base,'activation_4',val_generator,steps,56)\n",
    "feature2=extract_features(base,'activation_7',val_generator,steps,56)\n",
    "feature3=extract_features(base,'activation_10',val_generator,steps,56)\n",
    "feature4=extract_features(base,'activation_13',val_generator,steps,28)\n",
    "feature5=extract_features(base,'activation_16',val_generator,steps,28)\n",
    "feature6=extract_features(base,'activation_19',val_generator,steps,28)\n",
    "feature7=extract_features(base,'activation_22',val_generator,steps,28)\n",
    "feature8=extract_features(base,'activation_25',val_generator,steps,14)\n",
    "feature9=extract_features(base,'activation_28',val_generator,steps,14)\n",
    "feature10=extract_features(base,'activation_31',val_generator,steps,14)\n",
    "feature11=extract_features(base,'activation_34',val_generator,steps,14)\n",
    "feature12=extract_features(base,'activation_37',val_generator,steps,14)\n",
    "feature13=extract_features(base,'activation_40',val_generator,steps,14)\n",
    "feature14=extract_features(base,'activation_43',val_generator,steps,7)\n",
    "feature15=extract_features(base,'activation_46',val_generator,steps,7)\n",
    "feature16=extract_features(base,'activation_49',val_generator,steps,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Projection correlation & Distance correlation\n",
    "##################################################\n",
    "\n",
    "def get_arccos_1d(X):\n",
    "\n",
    "    # X -- a 1D array\n",
    "    \n",
    "    X = np.squeeze(X)\n",
    "    Y = X[:,None] - X\n",
    "    Z = Y.T[:,:,None]*Y.T[:,None]\n",
    "    n = len(X)\n",
    "    \n",
    "    a = np.zeros([n, n, n])\n",
    "    a[Z == 0.] = np.pi/2.\n",
    "    a[Z < 0.] = np.pi\n",
    "    \n",
    "    a = np.transpose(a, (1,2,0))\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "    \n",
    "    return a, A\n",
    "\n",
    "\n",
    "def get_arccos(X):\n",
    "\n",
    "    # X -- a 2D array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    cos_a = np.zeros([n, n, n])\n",
    "    \n",
    "    for r in range(n):\n",
    "        \n",
    "        xr = X[r]\n",
    "        X_r = X - xr\n",
    "        cross = np.dot(X_r, X_r.T)\n",
    "        row_norm = np.sqrt(np.sum(X_r**2, axis = 1))\n",
    "        outer_norm = np.outer(row_norm, row_norm)\n",
    "        \n",
    "        zero_idx = (outer_norm == 0.)\n",
    "        outer_norm[zero_idx] = 1.\n",
    "        cos_a_kl = cross / outer_norm\n",
    "        cos_a_kl[zero_idx] = 0.\n",
    "\n",
    "        cos_a[:,:,r] = cos_a_kl\n",
    "        \n",
    "    cos_a[cos_a > 1] = 1.\n",
    "    cos_a[cos_a < -1] = -1.\n",
    "    a = np.arccos(cos_a)\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "        \n",
    "    return a, A\n",
    "\n",
    "def projection_corr_1dy(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the projection correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*1 2D array\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def distance_corr(X, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    compute the distance correlation where\n",
    "    X -- an n*p 2D array\n",
    "    Y -- an n*p 2D array\n",
    "\n",
    "    return: a list of two elements: \n",
    "            [distance correlation, bias-corrected distance correlation]\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    if n < 4:\n",
    "        raise ValueError(\"sample size is less than 4.\")\n",
    "        \n",
    "    outer_diff_x = X[:, np.newaxis] - X\n",
    "    outer_diff_y = Y[:, np.newaxis] - Y\n",
    "    \n",
    "    a = np.linalg.norm(outer_diff_x, axis = 2)\n",
    "    b = np.linalg.norm(outer_diff_y, axis = 2)\n",
    "    \n",
    "    a0_bar = np.mean(a, axis = 0, keepdims = True)\n",
    "    a1_bar = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    b0_bar = np.mean(b, axis = 0, keepdims = True)\n",
    "    b1_bar = np.mean(b, axis = 1, keepdims = True)\n",
    "    b_bar  = np.mean(b, axis = (0,1), keepdims = True)\n",
    "    \n",
    "    A = a - a0_bar - a1_bar + a_bar\n",
    "    B = b - b0_bar - b1_bar + b_bar\n",
    "    \n",
    "    S_xy = np.sum(A*B)\n",
    "    S_xx = np.sum(A**2)\n",
    "    S_yy = np.sum(B**2)\n",
    "    \n",
    "    if S_xy * S_xx == 0.:\n",
    "        corr1 = 0.\n",
    "    else:\n",
    "        corr1 = np.sqrt(S_xy / np.sqrt(S_xx * S_yy))\n",
    "        \n",
    "    A_tilde = a - n*a0_bar/(n-2.) - n*a1_bar/(n-2.) + n*n*a_bar/((n-1.)*(n-2.))\n",
    "    B_tilde = b - n*b0_bar/(n-2.) - n*b1_bar/(n-2.) + n*n*b_bar/((n-1.)*(n-2.))\n",
    "    np.fill_diagonal(A_tilde, 0.)\n",
    "    np.fill_diagonal(B_tilde, 0.)\n",
    "    \n",
    "    S_xy_tilde = np.sum(A_tilde*B_tilde)\n",
    "    S_xx_tilde = np.sum(A_tilde**2)\n",
    "    S_yy_tilde = np.sum(B_tilde**2)\n",
    "    \n",
    "    if S_xy_tilde * S_xx_tilde == 0.:\n",
    "        corr3 = 0.\n",
    "    else:\n",
    "        corr3 = S_xy_tilde / np.sqrt(S_xx_tilde * S_yy_tilde)\n",
    "    \n",
    "    return [corr1, corr3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis1=distance_corr(feature1,label.reshape(-1,1))\n",
    "dis2=distance_corr(feature2,label.reshape(-1,1))\n",
    "dis3=distance_corr(feature3,label.reshape(-1,1))\n",
    "dis4=distance_corr(feature4,label.reshape(-1,1))\n",
    "dis5=distance_corr(feature5,label.reshape(-1,1))\n",
    "dis6=distance_corr(feature6,label.reshape(-1,1))\n",
    "dis7=distance_corr(feature7,label.reshape(-1,1))\n",
    "dis8=distance_corr(feature8,label.reshape(-1,1))\n",
    "dis9=distance_corr(feature9,label.reshape(-1,1))\n",
    "dis10=distance_corr(feature10,label.reshape(-1,1))\n",
    "dis11=distance_corr(feature11,label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30555807515636846, 0.08944141612844135]\n",
      "[0.3221554728382715, 0.09971918101818494]\n",
      "[0.3491906783757611, 0.11753164819858986]\n",
      "[0.4039298997665289, 0.1588345049898712]\n",
      "[0.4190955395154591, 0.17119731105829222]\n",
      "[0.42289699491793686, 0.1744235079645256]\n",
      "[0.43731026102893567, 0.18681553775043802]\n",
      "[0.4357218141559415, 0.18529716777572805]\n",
      "[0.4668576853879687, 0.21395927750371266]\n",
      "[0.4821415965232514, 0.22881181996600164]\n",
      "[0.503459287935368, 0.25051326905055343]\n"
     ]
    }
   ],
   "source": [
    "print (dis1)\n",
    "print (dis2)\n",
    "print (dis3)\n",
    "print (dis4)\n",
    "print (dis5)\n",
    "print (dis6)\n",
    "print (dis7)\n",
    "print (dis8)\n",
    "print (dis9)\n",
    "print (dis10)\n",
    "print (dis11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
