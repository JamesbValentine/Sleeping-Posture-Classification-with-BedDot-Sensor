{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c3f555",
   "metadata": {},
   "source": [
    "# Sleeping Dataset Analysis\n",
    "### Ruixuan Dong\n",
    "### 04/29/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e686117",
   "metadata": {},
   "source": [
    "写在前面： \n",
    "关于怎样做research：\n",
    " - 每周的update是合在一个文件中，还是分开写？比如每周的report/ipynb怎么版本更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e7ae1",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1 - Packages](#1)\n",
    "- [2 - Load Model and Process the Entire Dataset](#2)\n",
    "- [3 - Two day-to-day generalization scenarios](#3)\n",
    "    - [3.1 - 7/3 Data Set Selecting](#3-1)\n",
    "        - [3.1.1 - LightGBM](#3-1-1)\n",
    "    - [3.2 - One Day Out](#3-2)\n",
    "- [4 - GAN Method](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c02b8d",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b8f92",
   "metadata": {},
   "source": [
    "Begin by importing all the packages we'll need during this assignment. \n",
    "\n",
    "- [numpy](https://www.numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [pandas](https://pandas.pydata.org/) is the package for operating data frame with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
    "- `utilities` provides some functions to implemente data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be17f720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 18:11:24.439464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utilities import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d58ef9",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Load Model and Process the Entire Dataset\n",
    "\n",
    "**Problem Statement**: We'll be using the \"signal_1000_posture_4\" dataset in this study. There are 1000 colunms in total, where the first colunm represents a time stamp, the second colunm `Action` is set as label, and the last 998 colunms are features in this case. We'll try to use features to establish an efficient classifier and try to predict actions while sleeping much better. In the first step, we load the model fitted by training set obtained from the first 15 day's first 70% data.\n",
    "\n",
    "Let's test how this model performs on the whole dataset. Load the data by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877ca667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 18:11:36.890100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load the model fitted with data augmentation, which was obtained based on last week work.\n",
    "model = keras.models.load_model('my_model.h5')\n",
    "# Load the entire data set\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, dataset = load_larger_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486f7f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go_to_the_bed</th>\n",
       "      <td>8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_right_side</th>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_left_side</th>\n",
       "      <td>2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_stomach</th>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "Action                    \n",
       "go_to_the_bed         8975\n",
       "sleep_on_right_side   2688\n",
       "sleep_on_left_side    2571\n",
       "sleep_on_stomach      1882"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset.iloc[:, 1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac52def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 3s 5ms/step\n",
      "0.49140085256504484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# fit the scaler to your dataframe and transform it\n",
    "test_x_std = scaler.fit_transform(test_set_x_orig)\n",
    "test_x = pd.DataFrame(test_x_std)\n",
    "test_set_y = transform_label(test_set_y_orig)\n",
    "\n",
    "result = model.predict(test_x)\n",
    "tmp = np.argmax(result, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_set_y,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde6d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6483 1296 2185 2403]\n",
      " [ 458  152  198  152]\n",
      " [  90   33   41   30]\n",
      " [  47   19    9   10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "NN_confusion_matrix = confusion_matrix(test_set_y, tmp).T\n",
    "print(NN_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c847c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go_to_the_bed</th>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_stomach</th>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_left_side</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_right_side</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "Action                    \n",
       "go_to_the_bed         1897\n",
       "sleep_on_stomach       382\n",
       "sleep_on_left_side     138\n",
       "sleep_on_right_side     93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_set_y_orig.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aeec186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go_to_the_bed</th>\n",
       "      <td>7078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_right_side</th>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_left_side</th>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_stomach</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "Action                    \n",
       "go_to_the_bed         7078\n",
       "sleep_on_right_side   2595\n",
       "sleep_on_left_side    2433\n",
       "sleep_on_stomach      1500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_set_y_orig.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945333b",
   "metadata": {},
   "source": [
    "Propobably since the distribution of training set and new testing set are different, the accuracy on testing set based on the old model is not good, espcially consdiering the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a035d0",
   "metadata": {},
   "source": [
    "<a name = '3'></a>\n",
    "## 3 - Two day-to-day generalization scenarios\n",
    "\n",
    "<a name = '3-1'></a>\n",
    "### 3.1 - 7/3 Data Set Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206585ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_larger_dataset_first_scenario():\n",
    "    dataset = pd.read_csv('signal_1000_posture_4.csv')\n",
    "    dataset = dataset.reset_index(drop = True)\n",
    "    total_rows = dataset.shape[0]\n",
    "    train_nrows = int(total_rows * 0.7)\n",
    "\n",
    "    train = dataset.iloc[:train_nrows, :]\n",
    "    test = dataset.iloc[train_nrows: , :]\n",
    "\n",
    "    rows = train.values.tolist()\n",
    "    random.shuffle(rows)\n",
    "    train = pd.DataFrame(data=rows, columns=train.columns)\n",
    "\n",
    "    rows = test.values.tolist()\n",
    "    random.shuffle(rows)\n",
    "    test = pd.DataFrame(data=rows, columns=test.columns)\n",
    "\n",
    "    train_set_x_orig = train.iloc[:, 2:] # train set features\n",
    "    train_set_y_orig = train.iloc[:, 1] # train set labels\n",
    "\n",
    "    test_set_x_orig = test.iloc[:, 2:]# test set features\n",
    "    test_set_y_orig = test.iloc[:, 1] # test set labels\n",
    "\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, dataset, train, test\n",
    "\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, dataset, train_set, test_set = load_larger_dataset_first_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73ab80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go_to_the_bed</th>\n",
       "      <td>5896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_right_side</th>\n",
       "      <td>2526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_left_side</th>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_stomach</th>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "Action                    \n",
       "go_to_the_bed         5896\n",
       "sleep_on_right_side   2526\n",
       "sleep_on_left_side    1451\n",
       "sleep_on_stomach      1408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_set_y_orig.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8465bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go_to_the_bed</th>\n",
       "      <td>3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_left_side</th>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_stomach</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep_on_right_side</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "Action                    \n",
       "go_to_the_bed         3079\n",
       "sleep_on_left_side    1120\n",
       "sleep_on_stomach       474\n",
       "sleep_on_right_side    162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_set_y_orig.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "404ee1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_y = transform_label(train_set_y_orig)\n",
    "test_set_y = transform_label(test_set_y_orig)\n",
    "\n",
    "Y = pd.get_dummies(train_set_y)\n",
    "Y = Y.replace({True: 1, False: 0}).astype(float)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to your dataframe and transform it\n",
    "train_x_std = scaler.fit_transform(train_set_x_orig)\n",
    "train_x = pd.DataFrame(train_x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f940a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_first_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(1000), # dimension of X matrix\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(5000, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1000, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1000, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(200, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae9dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 60s 758ms/step - loss: 4.1047 - acc: 0.3844 - val_loss: 3.2730 - val_acc: 0.4124\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 59s 751ms/step - loss: 2.3948 - acc: 0.5532 - val_loss: 1.8958 - val_acc: 0.5560\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 58s 742ms/step - loss: 1.4798 - acc: 0.6361 - val_loss: 1.4066 - val_acc: 0.5976\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 60s 762ms/step - loss: 1.0571 - acc: 0.6996 - val_loss: 1.2096 - val_acc: 0.6216\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 59s 752ms/step - loss: 0.8135 - acc: 0.7576 - val_loss: 1.0998 - val_acc: 0.6467\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 61s 773ms/step - loss: 0.6682 - acc: 0.7996 - val_loss: 1.1215 - val_acc: 0.6564\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 60s 758ms/step - loss: 0.5954 - acc: 0.8255 - val_loss: 1.1988 - val_acc: 0.6591\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 61s 779ms/step - loss: 0.5181 - acc: 0.8497 - val_loss: 1.1521 - val_acc: 0.6756\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 60s 764ms/step - loss: 0.4224 - acc: 0.8832 - val_loss: 1.0809 - val_acc: 0.7016\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 60s 760ms/step - loss: 0.3850 - acc: 0.8926 - val_loss: 1.1133 - val_acc: 0.7208\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 60s 761ms/step - loss: 0.3176 - acc: 0.9143 - val_loss: 1.0962 - val_acc: 0.7247\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 60s 763ms/step - loss: 0.3131 - acc: 0.9124 - val_loss: 1.0271 - val_acc: 0.7430\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 60s 763ms/step - loss: 0.2473 - acc: 0.9364 - val_loss: 1.0392 - val_acc: 0.7306\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 59s 757ms/step - loss: 0.2229 - acc: 0.9433 - val_loss: 1.0675 - val_acc: 0.7430\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 59s 755ms/step - loss: 0.2296 - acc: 0.9443 - val_loss: 1.0910 - val_acc: 0.7383\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 61s 773ms/step - loss: 0.2153 - acc: 0.9450 - val_loss: 1.0965 - val_acc: 0.7371\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 58s 741ms/step - loss: 0.1941 - acc: 0.9539 - val_loss: 1.1117 - val_acc: 0.7380\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 59s 757ms/step - loss: 0.2039 - acc: 0.9491 - val_loss: 1.0545 - val_acc: 0.7424\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 60s 759ms/step - loss: 0.1461 - acc: 0.9663 - val_loss: 1.1761 - val_acc: 0.7421\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 60s 765ms/step - loss: 0.1635 - acc: 0.9604 - val_loss: 1.0661 - val_acc: 0.7548\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 59s 755ms/step - loss: 0.1512 - acc: 0.9649 - val_loss: 1.0905 - val_acc: 0.7545\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 60s 762ms/step - loss: 0.1547 - acc: 0.9644 - val_loss: 1.0610 - val_acc: 0.7448\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 59s 752ms/step - loss: 0.1401 - acc: 0.9668 - val_loss: 1.0537 - val_acc: 0.7468\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 59s 749ms/step - loss: 0.1376 - acc: 0.9691 - val_loss: 1.1153 - val_acc: 0.7581\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 59s 750ms/step - loss: 0.1304 - acc: 0.9695 - val_loss: 1.1556 - val_acc: 0.7554\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 59s 748ms/step - loss: 0.1430 - acc: 0.9669 - val_loss: 1.1187 - val_acc: 0.7572\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 59s 756ms/step - loss: 0.1346 - acc: 0.9704 - val_loss: 1.0584 - val_acc: 0.7663\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 60s 762ms/step - loss: 0.1412 - acc: 0.9672 - val_loss: 1.2052 - val_acc: 0.7533\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 63s 801ms/step - loss: 0.1329 - acc: 0.9710 - val_loss: 1.1272 - val_acc: 0.7471\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 62s 794ms/step - loss: 0.1204 - acc: 0.9751 - val_loss: 1.0875 - val_acc: 0.7516\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 63s 799ms/step - loss: 0.1237 - acc: 0.9737 - val_loss: 1.1746 - val_acc: 0.7598\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 60s 768ms/step - loss: 0.1182 - acc: 0.9754 - val_loss: 1.2096 - val_acc: 0.7581\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 61s 779ms/step - loss: 0.0974 - acc: 0.9804 - val_loss: 1.0716 - val_acc: 0.7687\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 64s 810ms/step - loss: 0.1056 - acc: 0.9783 - val_loss: 1.1289 - val_acc: 0.7675\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 63s 801ms/step - loss: 0.1125 - acc: 0.9752 - val_loss: 1.1463 - val_acc: 0.7604\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 63s 798ms/step - loss: 0.1082 - acc: 0.9763 - val_loss: 1.0888 - val_acc: 0.7728\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 61s 779ms/step - loss: 0.1108 - acc: 0.9748 - val_loss: 1.2544 - val_acc: 0.7554\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 61s 781ms/step - loss: 0.1192 - acc: 0.9737 - val_loss: 1.2486 - val_acc: 0.7619\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "first_model = create_first_model()\n",
    "callbacks=[\n",
    "           keras.callbacks.EarlyStopping(monitor='loss',\n",
    "           patience=5,\n",
    "           ),\n",
    "           keras.callbacks.TensorBoard(\n",
    "               log_dir='my_log_dir',\n",
    "               histogram_freq=1,\n",
    "               embeddings_freq=1,\n",
    "           )\n",
    "]\n",
    "\n",
    "first_history = first_model.fit(\n",
    "    train_x.values,\n",
    "    Y.values,\n",
    "    validation_split=0.3,\n",
    "    epochs=100,\n",
    "    # callbacks=callbacks,\n",
    "    batch_size=100,\n",
    "    callbacks=[callbacks],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712a869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step\n",
      "0.47094105480868664\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# fit the scaler to your dataframe and transform it\n",
    "test_x_std = scaler.fit_transform(test_set_x_orig)\n",
    "test_x = pd.DataFrame(test_x_std)\n",
    "\n",
    "result = first_model.predict(test_x)\n",
    "tmp = np.argmax(result, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_set_y,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a81a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2132  307  972   68]\n",
      " [ 353   97   50   62]\n",
      " [ 145   13   26   10]\n",
      " [ 449   57   72   22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "NN_confusion_matrix = confusion_matrix(test_set_y, tmp).T\n",
    "print(NN_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6806e41",
   "metadata": {},
   "source": [
    "After getting this result, I'm considering to balance the data set using some data augmentation method, like jitter, permutation, or window slice. But the result based on the model fitted by augmented data set is really bad, gaining an accuracy of 29% on testing set.\n",
    "\n",
    "Besides, there still exists a problem about running time. When I want to train larger model with more layers and more neurals, I found that I usually need to wait several hours until the parameter converged. Therefore, I trained much less models than last week I did, and this maybe also a reason for this week's bad result.\n",
    "\n",
    "Then, I tried LightGBM, which is created as a machine learning algorithm and can speed up much more. Although the results(accuracy and confusion matrix) are similar, the running time was less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16849bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = NN_augmentation_fit_44_days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23886da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = NN_augmentation_get_44_days_prediction()\n",
    "tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
